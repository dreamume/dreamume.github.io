---
layout:     post
title:      "Weekly 086"
subtitle:   "Algorithm: Distinct Subsequences II; Review: All of Netflix’s HDR video streaming is now dynamically optimized; Tips: System Design Interview - Rate Limiting; Share: Cracking the Mobile System Design Interview"
thumbnail-img: ""
date:       2023-12-27 21:10
author:     "dreamume"
tags: 		[it]
category:   it
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

# Table of Contents

1.  [Algorithm](#orgc12e928)
2.  [Review](#org7a4cbf9)
    1.  [比特率和质量比较](#org20e5204)
    2.  [成员收益](#orgd8c5152)
    3.  [HDR-VMAF 会开源吗？](#org2e39934)
    4.  [总结](#org0cc5dc2)
3.  [Tips](#orge9821fc)
4.  [Share](#org9bfc5d5)


<a id="orgc12e928"></a>

# Algorithm

Leetcode 940: [Distinct Subsequences II](https://leetcode.com/problems/distinct-subsequences-ii)

<https://dreamume.medium.com/leetcode-940-distinct-subsequences-ii-cfb43f1ffc6a>


<a id="org7a4cbf9"></a>

# Review

[All of Netflix’s HDR video streaming is now dynamically optimized](https://netflixtechblog.com/all-of-netflixs-hdr-video-streaming-is-now-dynamically-optimized-e9e0cb15f2ba)

高动态范围成像（HDR）视频带来更广亮度范围和更广的颜色范围，提供更绚丽的视觉体验。我们的动态优化编码发明依赖内容复杂度帮助获取优化的亮度质量

HDR 于 2016 年在 Netflix 出现且发展很快。然而，我们缺失 HDR 的度量感观质量（VMAF）的系统能力，因为 VMAF 受限于标准动态范围（SDR）视频信号

如之前的博客所说，我们开始开发一个 VMAF 的 HDR 变种；让我们称之为 HDR-VMAF。这个开发的一个及其重要的方面是预测 HDR 编码来产出训练数据。对大流行，导向一个方便的实验室 HDR 编码预测测试是唯一的挑战。我们临时起意作为杜比实验室合作效果的一部分且处理在校准条件下创造的参与者房间里使用高端 OLED 的 4K-HDR 内容做预测测试。HDR-VMAF 从属的细节超出了本文的范围且将在后续的博客中发布。现在，HDR-VMAF 的第一个版本在 2021 年内部着陆且我们一直在改进其度量

HDR-VMAF 的出现允许我们应用 DO 创建 HDR 流，例如，HDR-DO 编码。这之前，我们使用一个预定义比特率的固定梯子 - 对 HDR 视频流不管内容特征。我们在 2021 Q3-Q4 时在生产环境用 A/B 测试 HDR-DO 编码，在 2022 年早期改进梯子产生算法。我们从 2022 Q2 开始对现存的标题回填 HDR-DO 编码。在 2023 年 6 月整个 HDR 目录被优化。下图描述从固定比特率到 DO 编码的流量迁移

![img](../img/migration_of_traffic_from_fixed_ladder_encodes_to_DO_encodes.webp)


<a id="org20e5204"></a>

## 比特率和质量比较

HDR-VMAF 被设计为格式不可知的 - 它无视内容格式度量 HDR 视频信号的感知质量，例如，Dolby 图像或 HDR10。HDR-VMAF 聚焦信号特征（有损编码的结果）而不是显示特征，且它不包含流水线上的显示映射。显示映射是特别的色调映射应用于基于它自己特征的显示 - 峰值亮度、白水平、颜色范围等 - 且在比特流中基于信号的内容特征和/或元数据

HDR10 和杜比图像不同的两处是：1）预处理应用于编码之前的信号 2）元数据通知显示映射到不同的显示。这样，HDR-VMAF 将捕获效果 1）但忽略效果 2）。显示能力在各种各样 HDR 流内容的人口设备上大不同 - 这方面随着时间不同在设备各个因素上有变化比如环境光亮，视图距离，高端算法等。"VMAF 不兼容显示映射“意味着通过视频信号扩展整个颜色范围和呈现整个色彩范围的“理想显示”被计算成分数不需要显示映射。这个背景在查看速度 vs 质量曲线从属到这两个格式是有用的

以下显示从我们的 HDR 类目一对标题速度 vs 质量例子。我们呈现两个集合。每个集合我们显示杜比图像和 HDR10 的曲线。第一个集合对应一个美食烹饪系列节目显示世界上快节奏场景。第二个集合对应一个相对慢的喜剧系列节目；摄像机动作较慢。优化的编码通过各种速度 - 质量点对应不同比特率、空间解决方案和编码结果的凸面形式被选

为简化我们跳过注释梯子点及它们的空间解决方案，但从我们之前 SDR-4K 编码优化文章应用到这里来整体观察。固定梯子在空间解决方案爬升时比较缓慢，这样质量在两个连续 1080p 点或两个连续 4K 点之间大多保持平滑。另一方面，优化的梯子在比特率增加时呈现质量上尖锐地增长

固定梯子预定义 4k 比特率 - 8，10，12 和 16 Mbps - 它决定最大到 16 Mbps。另一方面，优化的梯子目标在比特率梯子运行顶部有非常高的质量水平，甚至如果内容复杂有更高的比特率成本，因此满足多数观看者。为了达到比固定梯子更高质量，HDR-HO 梯子，一般来说，相比较固定比特率梯子只占据 58% 的存储空间。这是通过更多高效空间梯子点获得，特别在高比特率领域。总之，压缩多个高比特率点使其更靠近并没有好处 - 例如，3 QHD（2560x1440）点放在 6 到 7.5 Mbps 范围跟随 4 个 4K 点在 8，10，12 和 16 Mbps，跟在固定梯子一样

![img](../img/dolby_vision_vide_quality_vs_bitrate.webp)

![img](../img/hdr10_video_quality_vs_bitrate.webp)

![img](../img/dolby_vision_video_quality_vs_bitrate_with_drama_series.webp)

![img](../img/hdr10_video_quality_vs_bitrate_with_drama_series.webp)

注意重要的是固定梯子编码有常量时长 GoPs 且由于影片边界与瞬时解码刷新（IDR）帧不对齐遭遇一些低效。DO 编码基于影片且 IDR 帧与影片边界对齐。对一个给定比率质量操作点，DO 处理帮助分配各种影片间的比特当最大化一个整体对象函数。多亏 DO 框架，在一个给定比率质量操作点，挑战影片可且在该点在比特率上爆发到编码水平限制


<a id="orgd8c5152"></a>

## 成员收益

我们用 A/B 测试固定和优化梯子；首先且最重要的确保领域的设备可处理新流和服务新流不导致意外的播放问题。A/B 测试也允许我们获得一个在质量体验（QoE）上改进的读取。总之，改进可总结为：

-   少于 40% 的重新缓存
-   对宽带限制和未限制的会话提供更高的视频质量
-   更低的初始化比特率
-   更高的初始化质量
-   更低的播放延时
-   转发视频质量的更少变动
-   更低的因特网数据使用，特别在移动和平板上


<a id="org2e39934"></a>

## HDR-VMAF 会开源吗？

是的，我们提交到支持的开源社区。当前的实现，然而，对我们内部流水线有大量裁剪。我们确保它是通用的，稳定的，且对社区来说易用的。另外，当前版本有一些算法限制我们在官方发布之前有改进处理。当我们发布时，HDR-VMAF 将在感知质量预测方面有更高的精确度，且更容易开箱即用


<a id="org0cc5dc2"></a>

## 总结

感谢 HDR-VMAF，我们能够优化我们的 HDR 编码。固定梯子 HDR 编码被优化的完全替代，缩减存储空间和因特网数据使用 - 且最重要的，改进我们成员的视频质量。改进跨所有设备类别都能看到，从 TV 到移动设备到平板


<a id="orge9821fc"></a>

# Tips

[System Design Interview - Rate Limiting (local and distributed)](https://www.youtube.com/watch?v=FU4WlwfS3G0)

假设有一个 Web 服务，有大量的用户。在网络上有可能导致“邻居噪音问题“，一些客户占用过多资源，另一些客户导致高延迟。解决办法之一是使用限速器。限速器帮助限制客户在给定时间内请求数限制。超过限制的请求要么立即被拒绝或处理被延迟

我们需要一个解决方案使得应用程序服务器可以互相通信且共享有多少客户端请求的信息

功能性需求：

-   对一个请求，我们的限速器需要给定结果，是否需要调节

非功能性需求：

-   我们需要限速器快速反应（快速做决定）
-   精确
-   可扩展（支持簇中任意数量的主机）

限速器必须快速决定，即使发生一些故障。因为许多服务要用到限速器，面试官可能会问到集成问题，这样我们的服务可无缝集成我们的限速器方案

我们首先用一个简单的解决方案开始。限速器间不需要通信，有一些规则，每个规则指定每秒内一个特殊客户端允许的请求数。这些规则由服务拥有者制定且存储在数据库中。规则获取器是一个后台进程定期推规则服务来检查是否有新规则或规则修改。规则获取器存储规则在主机内存中，当请求来时，第一件事是构建一个客户端唯一标识。我们简称它为键。这可能是一个注册的主机或远程 IP 地址或一些唯一确认客户端的属性信息的登录。键然后传递给限速器组件，限速器检查键与缓存中的规则，如果发现匹配，限速器检查最近一秒内客户端请求的数量是否低于规则指定的限制。如果没有超过，请求通过并进一步处理，否则就拒绝。这里还有 3 个选项。我们的服务可能返回一个特别的回复状态码，例如服务无效或太多请求。或者我们可让这个请求进入队列且延后处理。或我们可简单丢弃这个请求

面试官可能对限速器算法感兴趣且要求我们实现一个。或面试官可能对面向对象设计感兴趣且要求我们定义主类和库的接口。或面试官可能聚焦于分布式瓶颈解决方案和讨论服务主机如何互相共享数据

我们先讨论算法。有很多算法，如果感兴趣你可在 Google Guava RateLimiter 类中找。或想想如何应用固定和浮动窗口。但可能最简单的算法是 Token bucket 算法。该算法基于对填充 token 的桶的分析。每个桶有 3 个特征：能保存的最大 token 数值，当前 token 数和一个重填速度。每次请求来临，我们从桶中取出一个 token，如果桶中没有有效的 token，则请求被拒绝。桶以一个常量速度重填 token。bucket token 算法的好处是简单好实现

现在我们来看面向对象设计。让我们定义关键类和接口。JobScheduler 接口负责调度一个任务其每次运行几秒钟且从规则服务中获取规则。RulesCache 接口负责在内存中存储规则。ClientIdentifier 类构建客户的唯一识别码。RateLimiter 类负责决策制定。RetrieveJobScheduler 类实现 JobScheduler 类的接口，它负责实例化、开始和停止调度器，并运行获取规则的任务。对 Java，我们可利用 ScheduledExecutorService 接口作为一个调度器。TokenBucketCache 类存储 token 桶。我们可使用简单的例如字典来存储桶，或利用三方缓存实现，比如 Google Guava 缓存。ClientIdentifierBuilder 负责基于用户唯一信息构建一个键，例如登陆信息。有一些其他实现，比如基于 IP 地址。对 RateLimiter 类接口我们用 TokenBucketRateLimiter 类，负责在对应桶中允许客户端的请求。最后是 RetrieveRulesTask 类，负责获取所有这个服务的规则。我们看一下它们之间的交互。RetrieveJobScheduler 运行 RetrieveRulesTask，对规则服务做一个远程过程调用。它然后创建 token 桶并把它们放入缓存。当客户端请求到了主机，RateLimiter 首先对 ClientIdentifierBuilder 做一个调用来构建客户端的唯一识别码。然后它把这个键传给缓存并获取桶。最后一步是在桶上允许请求调用

簇中各主机实现可如下。在簇中每个主机知道簇中每个其他主机，并它们间共享消息。主机如何相互发现呢？当一个新主机被添加，其他主机如何知道？有一些处理用于主机发现。一个选项是使用一个三方服务监听每个主机的心跳。当心跳到来时，主机保持在系统中的注册。如果心跳没来，服务反注册不再活跃的主机。并且簇中所有主机向这个三方服务请求所有成员的列表。另一个选项是解析一些用户提供的信息。例如，用户指定一个 VIP 且因为 VIP 知道所有它之前的主机，我们可使用这个信息获取所有成员。或我们可依赖一个稍微缺乏灵活度但依然是一个好的选项的，用户通过配置文件提供成员列表。每次这个列表改变时我们需要一个方法在所有簇节点中使用这个文件。全网广播是相对直接的实现。但主要问题是这个处理没有可扩展性。消息的数量相对簇中主机数是二次方地增长。这个处理对小型簇可很好地工作，但我们将不能在大型簇中支持。其他方法的一个选项是使用一个 gossip 协议。这个协议基于流行病扩散的方式。计算机系统典型地用一些随机端点实现这类协议：对一个给定的频率，每个机器随机选择另一个机器且共享数据。这样，Yahoo 的限速解决方案使用这个方法。另一个选项是使用分布式缓存簇。例如，Redis。或我们可实现自定义分布式缓存解决方案。这个处理的优点是分布式缓存簇相对小且我们的服务簇可独立扩展。这个簇可在组织多个不同服务团队中共享。或每个团队可构建他们自己的小簇。另一个方法也依赖一个三方组件。一个协调服务帮助选择一个领导者。选择一个领导者帮助减少簇中消息广播数量。领导者要求每个主机发送它所有的信息。然后它计算并送回最后的结果。这样，每个主机只需要跟一个领导者通信或一系列领导者，每个领导者负责它自己的键范围。共识算法比如 paxos 和 raft 可被用于实现协调服务。但主要的问题是我们需要建立并维护协调服务。协调服务是一个非常典型地复杂组件，非常依赖有且只有一个领导者被选举中。但这对我们的系统真正是一个需求吗？

我们先使用一个简单的算法选举一个领导者。但因为算法简单，它可能不能保证有且只有一个领导者。这样我们会导致多个领导者被选举出来。这是一个问题吗？事实上，不是。每个领导者可计算速度且与其他主机共享。这将导致不必要的消息，但每个领导者将有它自己正确的全局速度视图。对消息广播讨论的最后，我将谈论通信协议。主机如何相互通信？

我们有两个选项：TCP 和 UDP。TCP 协议保证数据转发且保证包将被以相同的顺序转发。UDP 协议不保证你能得到所有的包且顺序不保证。因为 UDP 没有所有的错误检测，所以它速度更快。哪个更好？都是好的选择。如果我们想要限速解决方案更精确，并接受一个小的性能为代价，我们选择 TCP。如果我们可接受一个相对欠精确的解决方案，但更快，选择 UDP

我们如何集成服务中的所有这些解决方案？有两个选项。都非常标准。我们可运行限速器作为服务进程的一部分或用单独的进程。对前者，限速器作为一系列类分布，一个库集成服务代码。第二个选项我们有两个库，一个后端进程和一个客户端，负责在服务进程和后端进程间通信。客户端集成服务代码。对前者的优点，它更快，我们不需要任何进程间调用。后者更有利于编程，限速器后端进程可与服务实现所用的编程语言不同，我们不需要在代码层面进行集成。我们需要限速器客户端代码兼容服务代码用的语言。限速器进程使用它自己的内存空间。这个隔离更好地帮助对服务和后端的行为控制。例如，后端进程可存储许多桶在内存，但服务进程不需要这些桶空间，这使得服务内存分配更可预测。另一个好的原因，你可看到这样的隔离有利于回答集成团队的各种问题

理论上，许多 token 桶在内存中创建和存储是可能的。实际上，我们不需要在内存中保持在一段时间内没有请求的桶。例如，客户端发起第一个请求我们创建一个桶。后续继续有请求发送到该桶，我们继续保持该桶。如果之后的几秒钟内没有到该桶的请求，我们可从内存中移除该桶。当后续有需要时再创建。后端进程会故障，导致簇中其他主机缺失该故障进程的可见性。结果，故障进程的主机离开组且继续限制请求而没有跟其他主机通信。这样导致总体上更少的请求被限制。当网络分区时我们有相似的情形，当簇中一些主机不能广播消息到组中其他主机。对规则管理，我们可能需要引入一个自服务工具，这样服务团队在需要时可创建，更新和删除他们的规则。对同步，我们需要做一些事情。首先，我们在 token 桶中同步。在这样的类中用线程安全的实现是更好的办法，例如使用原子操作。如果有太多的桶存储在缓存中，我们想要删除未使用的并在要使用时再创建，我们需要同步。这样，我们可用并行哈希表

我们服务的什么客户端应该限制调用？有一些选项。客户端可对这样的请求队列处理且之后重发送它们。或可重试限制的请求。一个更聪明的方法是指数回溯和 jitter。该算法对重试的请求添加一个到最大回溯时间的等待时间。即我们重试请求几次，每次重试时间间隔会更长。jitter 添加随机间隔到重试时间中


<a id="org9bfc5d5"></a>

# Share

[Cracking the Mobile System Design Interview (iOS & Android)](https://themobileinterview.com/cracking-the-mobile-system-design-interview/)

对 FAANG 公司（Facebook/Meta, Amazon, Apple, Netflix, Google），系统设计面试变得流行因为大技术公司已引入数十年。这些面试对多数后端角色是任意面试进程的一个标准部分。现在，轮到移动端工程师了

