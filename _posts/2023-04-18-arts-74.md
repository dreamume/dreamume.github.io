---
layout:     post
title:      "Weekly 074"
subtitle:   "Algorithm: Minimum Reverse Operations; Review: Making your code faster by taming branches; Tips: Finding a needle in Haystack; Share: "
thumbnail-img: ""
date:       2023-04-18 12:30
author:     "dreamume"
tags: 		[it]
category:   it
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

# Table of Contents

1.  [Algorithm](#org3bbe7a0)
2.  [Review](#orgad0eb2c)
    1.  [关键要点](#org6e0a7fa)
    2.  [分支预测不容易被愚弄](#orge4e6e4c)
    3.  [分支预测错误可能代价很高](#org3035dad)
    4.  [避免分支](#orgbb241ba)
    5.  [结论](#orgcb11034)
3.  [Tips](#org4317675)
    1.  [简介](#org14cad4a)
    2.  [背景和之前的设计](#org05a8629)
        1.  [背景](#org0f94d57)
        2.  [基于 NFS 的设计](#orgaa2234a)
4.  [Share](#org5da1016)


<a id="org3bbe7a0"></a>

# Algorithm

Leetcode 2565: [Minimum Reverse Operations](https://leetcode.com/problems/minimum-reverse-operations)

<https://dreamume.medium.com/leetcode-2612-minimum-reverse-operations-69e9ec1c4ae2>


<a id="orgad0eb2c"></a>

# Review

Making your code faster by taming branches

<https://www.infoq.com/articles/making-code-faster-taming-branches/>


<a id="org6e0a7fa"></a>

## 关键要点

-   为更好的性能，现代处理器预测分支且执行猜测的指令。这是强有力的优化
-   程序员可能被错误低估分支预测错误对评测代码的代价，当人造的数据太短或太多预测时。分支错误预测的效果会很大。幸运地是，通常能够完全避免分支
-   重写你的代码使用更少的分支会使代码有更一致性的速度
-   需要适合的错误分支预测处理来优化性能

多数软件代码包含条件分支。在代码中，它们出现在 if else，循环和 switch 中。当统计一个条件分支，处理器检查一个条件且跳转到一个新的代码路径，如果分支被采用，或者继续执行接下来的指令。不幸地是，处理器可能只在执行玩之前的所有指令后知道是否一个跳转是必须的。为更好的性能，现代处理器预测分支且执行猜测的指令。这是一个强有力的优化。

然而猜测执行有一些限制。例如，在错误预测后处理器必须丢弃已作的工作且当分支预测失败时重新开始一次。幸运地是，处理器尽可能擅长识别范型且避免错误预测。尽管如此，一些分支本能地很难预测且它们会导致一个性能瓶颈


<a id="orge4e6e4c"></a>

## 分支预测不容易被愚弄

程序员可能被错误低估分支预测错误对评测代码的代价，当人造的数据太短或太多预测时。现代处理器能学习预测数千个分支，这样一个短的测试可能不能暴露分支预测的代价，即使数据看上去是随机的

让我们考虑一个例子。假设我们想要解码十六进制数字。我们想要获得对应的整数值。一个合理的 C 函数如下

    int decode_hex(char c) {
      if (c >= '0' && c <= '9') return c - '0';
      if (c >= 'A' && c <= 'F') return c - 'A' + 10;
      if (c >= 'a' && c <= 'f') return c - 'a' + 10;
    
      return -1;
    }

一个程序员可随机产生一个字符串评测这样的函数。例如，在 C 中，我们可重复调用 rand 函数且选择 22 个十六进制数字的一个

    char hex_table[] = {'0', '1', '2', '3', '4', 
                        '5', '6', '7', '8', '9', 
                        'a', 'b', 'c', 'd', 'e', 'f',
                        'A', 'B', 'C', 'D', 'E', 'F' };
    
    void build_random_string(size_t length, char *answer) {
      for (size_t i = 0; i < length; ++i)
        answer[i] = hex_table[rand() % sizeof(hex_table)];
    
      return answer;
    }

然后可记录解码这些数字的时间。对好的测量，一个程序员可能运行这个测试几次且计算平均值。在多次测试之后，让我们描出对不同的字符串长度（1000，2000，&#x2026;）每十六进制数字的错误预测分支数量。重要的是，我们重使用所有实验中的相同的输入字符串

使用一个标准服务器处理器（AMD Rome），我们发现对一个包含 3000 数字的字符串，在不到 20 次实验后每数值的错误预测分支数降到 0.015（1.5%）。对更短的字符串（1000 数字），错误分支预测数降得更快，在 8 次实验后降到 0.005。即一个标准服务器处理器在少于 10 次解码后可学习预测 1KB 十六进制随机字符串产生的所有分支

![img](../img/mispredicted_branches_in_trial.webp)

支持 just-in-time 编译器（比如 Java 或 Javascript）的编程语言中，它重复评测直到编译器优化了代码：如果测试太短，即使输入是随机的，我们也存在低估分支预测错误的代价

类似的，用人造数据运行测试，即使当数据集特别大，可能使得处理器高精度预测分支。假设我们使用从 0 到 65536 的数字替代随机字符串：0x00, 0x01, &#x2026;

分支预测必须在数字和字符出现时预测。结果字符串（0000100021003100421052106310731084219421a521b521c631d631e731f7310842 &#x2026; 8ce18ce29ce39ce4ade5ade6bde7bde8cef9cef &#x2026;）不是随机的，但它使得预测数字和字符范型有效。使用相同的 AMD Rome 处理器，我们发现在这样一个长度为 131072 的字符串上错误预测分支的数量在第一次实验时接近为 0：每字节 0.002 次分支预测错误


<a id="org3035dad"></a>

## 分支预测错误可能代价很高

错误分支预测的影响可能会很大。让我们使用我们收集的不同长度随机十六进制字符串，且标出每输入数字 CPU 周期数及错误分支预测数。我们发现 CPU 周期数在每十六进制数字 5 周期到 20 周期变化，取决于错误预测分支数

![img](../img/mispredictions_and_cycles_when_test_with_random_digit.webp)

我们还不应该得出大量的分支预测错误是一个必要的考量因为可能有更重要的考量。例如，考虑一个大数组中的二进制搜索。限制是主存中内存访问延迟比分支错误预测成本更高


<a id="orgbb241ba"></a>

## 避免分支

性能分析工具，如 perf(Linux)，xperf(Windows) 和 Instruments (macOS)，可测量分支预测错误数。如果你手里有相关的问题，是否分支是一个问题呢？

幸运地是，通常可以完全避免分支。例如，为解码十六进制数字，我们可使用一个数组查找

    int digittoval[256] = {
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, 0,  1,
        2,  3,  4,  5,  6,  7,  8,  9,  -1, -1,
        -1, -1, -1, -1, -1, 10, 11, 12, 13, 14,
        15, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, 10, 11, 12,
        13, 14, 15, -1,...};
    int hex(unsigned char c) {
      return digittoval[c];
    }

这个函数可编译为一个指令，没有分支。它可通过检查负整数来验证不合适的输入

这样，我们通常使用内存来替代分支：我们预计算分支并存储到一个简单数据结构中，比如数组

另一个避免分支的策略是做一些推测工作并抛出它们。例如，假设我们想要从整数输入数组中擦除所有负整数，在 C 中，我们可用一个循环和一个分支

    for(size_t i = 0; i < length; i++) {
        if(values[i] >= 0) {
            values[pos++] = values[i];
        }
    }

我们假设这个函数叫 branchy，该代码检查输入并选择性地拷贝到新位置。如果我们很难预测哪个整数是负数，那这个代码是不高效的

幸运地是，多数编译器可以使用如下代码避免分支

    size_t sign(int v) {
        return (v >= 0 ? 1 : 0);
    }
    
    for(size_t i = 0; i < length; i++) {
      values[pos] = values[i];
      pos += sign(values[i]);
    }

这个函数我们暂时称为 branchless。branchless 和 branchy 函数还是有点差异，编译器不能相互转换

即使不能移除所有分支，减少分支数用 "almost always taken" 和 "almost never taken" 可帮助编译器更好地预测剩下的分支。例如，如果我们使用循环一个个地解码，则在循环中我们对每个数字有一个预测分支

    for (i = 0; i < length; ++i)
      int code = decode_hex(input[i]);
    // ...

对长的输入字符串，我们可减少减少一半的预测分支通过每次循环迭代处理两个输入字符

    for (; i + 1 < length; i += 2) {
      int code1 = decode_hex(input[i]);
      int code2 = decode_hex(input[i + 1]);
    // ...
    }

在一个 AMD Rome 处理器上对 5000 数字的输入字符串，我们发现多次实验之后对简单循环的分支预测错误数是每数字 0.230，而对一次迭代处理两个数字的版本只有 0.165，减少了 30%

![img](../img/mispredicted_branches_trial_number_experiment.webp)

对这个现象的一个可能的简单解释是处理器使用历史上最新的分支预测将来的分支。无信息分支会让处理器减少做出好的预测的能力

当不能避免难的预测分支，我们可通常减少它们的数量。例如，当比较两个日期，把它们格式化为 YYYYMMDD 会比较方便，且比较结果的 8 字节字符串作为 64 为整数比较，可只使用一个指令


<a id="orgcb11034"></a>

## 结论

对包含困难预测分支的代码进行评测是困难的，且程序员有时低估分支的代价。用更少的分支重写代码会让代码有更一致性的速度。预测错误分支的合适处理需要优化性能


<a id="org4317675"></a>

# Tips

[Finding a needle in Haystack: Facebook’s photo storage](https://goo.gl/edj4FL)

本文描述 Haystack，一个为 Facebook 图像应用程序优化的对象存储系统。Facebook 当前存储了超过 2600 亿个图片，大约 20PB。用户每周上传 10 亿个新图片（约 60 TB）且峰值时 Facebook 每秒处理超百万个图片。Haystack 提供了一个比之前的方式成本低且更高性能的解决方案，其对基于 NFS 的存储应用和网络有杠杆效果。我们重点关注到传统设计因 metadata 的查询导致过多的磁盘操作。我们小心地减少每图片 metadata 的操作让 Haystack 存储设备可在内存中处理所有 metadata 查询。这个处理节省磁盘操作来读取实际的数据并增加总体吞吐量


<a id="org14cad4a"></a>

## 简介

共享图片是 Facebook 最流行的特性之一。到目前，用户已上传超过 650 亿张图片，Facebook 成为了全球最大的图片分享网站。对每个上传的图片，Facebook 会生成并存储四个不同大小的图片，转换了超过 2600 亿张图片和超过 20PB 数据。用户每周上传 10 亿张新图片（约 60 TB）且 Facebook 在峰值时每秒提供超过百万张图片。我们期望该数字会继续增长，则图片存储对 Facebook 的架构是一个显著的挑战

本文呈现 Haystack 的设计和实现。Facebook 的图片存储系统已在生产环境运营了 24 个月。Haystack 是一个对象存储，我们设计作为 Facebook 共享图片，其数据写一次，多次读，从不修改且很少删除。我们开发我们自己的图片存储系统因为传统的文件系统在我们的工作负载下性能低下

在我们的经验中，我们发现传统的 POSIX 文件系统的缺点是目录和每文件 metadata。对这样 metadata 的图片应用程序，比如权限，是无用的，因此浪费存储空间。更重要的成本是为了找到文件需要把文件的 metadata 从磁盘读到内存。对小规模不明显，但对数十亿图片和 PB 级别的数据，访问 metadata 是吞吐量的瓶颈。我们发现这是我们使用 NAS 的关键问题。需要一些磁盘操作来读取一个图片：一个（通常更多）用来转换文件名到 inode 号，另一个从磁盘读 inode，最后一个读文件本身。对 metadata 使用磁盘 IO 是我们读取吞吐量的限制因素。观察到实际上这个问题引入了一个额外的成本，我们需要依赖 CDN 比如 Akamai，来解决主要的读数据量

为此，我们设计 Haystack 来达到以下四个主要目的

高吞吐量和低延迟：我们的图片存储系统需要支撑用户的请求。超过我们处理容量的请求要么被忽略，这对用户体验来说是不可接受的，要么被 CDN 处理，其成本高且得到一个消失的返回。更进一步，图片需要快速提供来得到好的用户体验。Haystack 通过每次读取请求最多一次磁盘操作来获得高吞吐量和低延迟。我们通过保持所有 metadata 到内存来实现，我们戏剧化地缩减每图片 metadata 来找到磁盘上的文件

容错：在大规模扩展系统，故障每天都在发生。我们的用户的图片需要有效，即使在有不可避免的服务器崩溃和磁盘故障的情况下。有可能一整个数据中心失去电力或一个跨国连接服务。Haystack 复制每个图片到地理上不同的地区。如果我们失去了一台机器，我们引入另一台替代，必要时拷贝冗余数据

高效成本：Haystak 有更好地执行且比我们之前的 NFS 方案有更低的成本。我们用两个维度量化我们的节省成本：Haystack 有用存储的每 TB 成本和 Haystack 有用存储的每 TB 常规读速度。在 Haystack 中，每有用 TB 成本低 28% 且每秒处理超过 4 倍读速度相比之前的 NAS 应用程序

简单：在生产环境中我们不能夸大直接实现和维护的设计的能力。Haystack 是一个新系统，缺少生产线上多年的测试，我们特别关注于让它保持简单。简单使得我们能在几个月时间中开发一个工作系统而不是几年

这个工作描述了从概念到实现一个产品质量系统服务一天数十亿图片的 Haystack 的经验。我们的三个主要贡献是：

-   Haystack，一个对象存储系统优化了高效地存储和提取数十亿图片
-   在构建和扩展一个不高昂，可靠和有效的图片存储系统上学到了一些经验教训
-   Facebook 图片共享应用程序的请求特征


<a id="org05a8629"></a>

## 背景和之前的设计

在本章节中，我们描述之前的架构和我们学到的主要经验。由于篇幅限制，对之前设计的讨论省略了一些生产级开发的细节


<a id="org0f94d57"></a>

### 背景

我们开始简介对 Web 服务器，CDN 和存储系统如何交互服务一个特殊网站的图片。下图描述了当一个用户访问一个包含图片的页面直到它从磁盘位置下载的步骤。当访问一个页面用户浏览器首先发送一个 HTTP 请求到一个 Web 服务器，浏览器收到响应进行渲染。对每个图片 Web 服务器构建一个 URL 来定位从哪里下载。对一个流行的网站这个 URL 通常指向一个 CDN。如果 CDN 有图片数据缓存则 CDN 立即响应数据。否则，CDN 检查 URL，其嵌入了足够的信息来从网站存储系统获取图片。CDN 然后更新它的缓存数据且发送图片到用户浏览器

![img](../img/typical_photo_arch_design.png)


<a id="orgaa2234a"></a>

### 基于 NFS 的设计

在我们的首个设计中我们实现了使用一个基于 NFS 的图片存储系统。本节后续内容提供更多该设计的细节，主要的经验我们学到的是 CDN 本身不提供实际的解决方案供应一个社交网络网站的图片。CDN 高效供应最热点的图片 - 最近上传的图片 - 但一个社交网络网站比如 Facebook 也有大量请求对不那么热点的内容，我们称之为长尾。长尾请求是一个重要的流量，其请求 CDN 上缺失导致访问后台图片存储系统主机。把长尾所有图片缓存是一个非常方便的办法，但这需要非常大的缓存因此成本高

我们基于 NFS 的设计存储每个图片到一系列商业 NAS 应用程序里它自己的文件中。一系列机器，图片存储服务器，加载通过 NFS 的 NAS 应用程序导出的所有卷积。下图展示了这个架构且显示图片存储服务器处理图片的 HTTP 请求。从一个图片的 URL 中一个图片存储服务器提取卷积和全路径到文件，读取 NFS 数据且返回结果到 CDN

![img](../img/nfs_based_design_of_photo_storage_arch.png)


<a id="org5da1016"></a>

# Share

