---
layout:     post
title:      "Weekly 088"
subtitle:   "Algorithm: Coiunt the Number of House at a Certain Distance II; Review: Incremental Processing using Netflix Maestro and Apache Iceberg; Tips: System Design Interview - Distributed Message Queue; Share: How to make an iOS App Secure?"
thumbnail-img: ""
date:       2024-02-05 22:40
author:     "dreamume"
tags: 		[it]
category:   it
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

# Table of Contents

1.  [Algorithm](#org8b04544)
2.  [Review](#orgfe0cd1c)
    1.  [简介](#org69e9911)
    2.  [处理概述](#orgb554c4a)
        1.  [一般概念](#orgd1b8c32)
3.  [Tips](#org071414d)
4.  [Share](#org2b6c6f4)


<a id="org8b04544"></a>

# Algorithm

Leetcode 3017: [Count the Number of House at a Certain Distance II](https://leetcode.com/problems/count-the-number-of-houses-at-a-certain-distance-ii/)

<https://dreamume.medium.com/leetcode-3017-count-the-number-of-house-at-a-certain-distance-ii-5ca5a363e2e4>


<a id="orgfe0cd1c"></a>

# Review

[Incremental Processing using Netflix Maestro and Apache Iceberg](https://netflixtechblog.com/incremental-processing-using-netflix-maestro-and-apache-iceberg-b8ba072ddeeb)

递增地进程是在工作流中处理新或改变的数据一种处理。关键的优势是它只递增地处理新添加或更新到一个数据集的数据，而不是重处理完整的数据集。这不只减少了计算资源的成本但也以显著的方式缩减了执行时间。当工作流执行有更短的时长，失败的机会和手工干预都会减少。它也通过简化现有的工作流和解锁新的范型来改进了工程生产率

本博客中，我们谈论在 Netflix 中工作流的落地和挑战。我们将显示我们如何通过使用 Netflix Maestro 和 Apache Iceberg 构建一个清晰和高效的递增处理解决方案（IPS）。IPS 提供数据精度、数据刷新和在工作流中回填用户和处理许多挑战的递增处理支持。IPS 启动用户用最小的改变继续使用数据处理范型


<a id="org69e9911"></a>

## 简介

Netflix 在所有阶段都依赖数据来强化它的业务。是否在分析 A/B 测试，优化工作室产品，训练算法，在内容获取，检测安全缺陷或优化支付，结构化和精确数据上都是基础的。当我们的业务全球扩展，数据需求地增长和可扩展地递增处理低延时开始并在一起。数据集拥有者通常面对三个常见的问题：

-   数据新鲜：iceberg 表中的大数据集需要快速处理和精确产生洞察来启动更快的产品决策。小时级的处理语法及通过数据平台工具提供的时间戳验证有效性的水印或数据信号显著满足很多用例，但对低延时批处理不是最好的。在 IPS 之前，数据平台没有追踪状态和数据集进度作为一个解决方案易于使用。这导致了一些内部解决方案比如 Psyberg。这些内部库通过捕获改变的分区处理数据，其只工作在特殊的用例上。另外，库跟用户业务逻辑紧密耦合，常常导致更高的迁移成本，维护成本和需要数据平台团队更重的协调工作
-   数据精确度：迟到的数据导致数据集处理在过去的时候，使得数据变得不完整和结果不精确。为补偿，ETL 工作流常常使用一个回看窗口，基于在某个时间窗口上重处理数据。例如，一个工作重处理过去 3 天聚集的数据因为它假设有迟到的数据，但 3 天之前的数据不值得重处理
-   回填：回填数据集在大数据处理时是一个常见的操作。这需要在调度处理前重产生一个历史时间段的数据。回填需要由各种因素导致，例如（1）上流数据集由于业务逻辑它的数据流水线改变导致重生成（2）数据流水线中业务逻辑改变（3）一个新的度量被创建需要产生一段历史时间范围数据（4）历史数据被发现丢失 等

这些挑战当前作为子优化处理且通过独立本地团队以更少成本高效的方式填满需求，比如

-   回看：这是一个一般化且简单的处理，数据工程师用来解决数据精度问题。用户配置工作流来读窗口中的数据（例如，过去 3 小时或 10 天）。窗口基于用户域知识设置以便用户有高自信使得迟到的数据将被包含或没关系（例如，数据太晚到达很有用）。它确保时间和技术资源的正确性
-   每范型：用户构建使用 Maestro 支持的回填工作流。对单个工作流产生的回填数据工作很好。如果流水线有多个阶段或多个下流工作流，用户不得不对每个手工创建回填工作流且需要重要的手工操作

这里的递增处理解决方案（IPS）描述为被设计处理以上的问题。设计目标是提供一个清晰且容易采用的解决方案来处理递增处理来确保数据新鲜度，数据精确度和提供容易的回填支持

-   数据新鲜度：在微批处理方式（例如，15 分钟间隔）及带状态追踪功能下提供对调度工作流的支持
-   数据精确度：提供处理所有迟到数据的支持来获得多模时间和成本高效下有显著改进性能的业务需要的数据精确度
-   回填：提供被管理的回填支持来构建，监控和有效化回填，包括自动从上流到下流工作流中繁殖变动，来极大地改进工程产品化（例如，几天或几周的工程工作来构建回填工作流 vs 被管理的回填的一个点击）


<a id="orgb554c4a"></a>

## 处理概述


<a id="orgd1b8c32"></a>

### 一般概念

递增过程是批处理数据的方法 - 但只针对新和修改的数据。为支持递增过程，我们不只需要捕获递增数据改变的处理也需要跟踪它们的状态（例如，是否一个改变被一个工作流处理或未处理）。它必须知晓改变且从源表中捕获改变且然后保持追踪这些改变。这里，改变意味着比新数据本身更多。例如，在聚集目标表上的一行需要从源表与聚集行相关的所有行。同样，如果有多个源表，通常从所有输入表的改变数据的联合给出了完整的改变数据集。这样，改变信息的捕获必须包括在源表中未改变行的所有相关数据。由于之前提及的复杂度，改变追踪不能简单通过使用一个单一水印获得。IPS 必须以很好的粒度追踪这些捕获的改变

从源表中的改变可能影响各种方式下目标表的转换结果

-   如果目标表中的一行源于源表中的一行，新捕获数据的改变将完整化工作流流水线的输入数据集
-   如果目标表中一行源于源表的多行，捕获新数据将只告诉我们行不得不重处理。但需要 ETL 的数据集超过改变数据本身。例如，一个基于账号 ID 的聚集需要源表中关于该账号 ID 的所有行。改变数据集将告诉我们哪个账号 ID 被改变且然后用户业务逻辑需要在改变数据中加载那些账号 ID 相关的所有数据
-   如果目标表中的一行源于数据超过了改变数据集，例如，源表和其他表的集合，新的捕获数据依然有用且可显示一段范围数据被影响。然后工作流将基于范围重处理数据。例如，假设我们有一个表保持被该天对给定账号分区的聚集的时间的视图。如果视图时间是 3 天前由于迟到而现在才更新，则对接下来两天的视图时间必须重计算这个账号。这种情况下，迟到捕获的数据将告诉我们开始重计算，其比通过猜测估计过去 X 天的重计算所有更精确，X 是通过业务域知识决定的一个截断回看窗口

一旦改变信息（数据或范围）被捕获，一个工作流不得不用一个更复杂的方式写数据到目标表因为简单的插入覆写方式不起作用。有两个替代方案：

-   合并范型：在一些计算框架，例如，Spark 3，支持 MERGE INTO 来允许新数据被合并到现存的数据集。对递增处理能解决写的问题。注意工作流/步骤当使用 MERGE INTO 时可安全重启不用担心重复数据被插入
-   追加范型：用户可只使用追加写（例如，INSERT INTO）来添加新数据到现存的数据集。一旦处理完成，追加的数据被提交到表。如果用户想要重跑或重构建数据集，它们将跑一个回填工作流来完成覆写目标数据集（例如，INSERT OVERWRITE）

另外，IPS 在很多用例下将自然地支持回填。下流工作流（如果没有业务逻辑改变）将由于回填而触发数据改变。这启动在多阶段下流水线的回填数据的自动广播。注意回填支持在本博客中不会谈及，这将放在另一个博客中


<a id="org071414d"></a>

# Tips

[System Design Interview - Distributed Message Queue](https://www.youtube.com/watch?v=iJLL-KPqBpM)

有两个 Web 服务被称作生产者和消费者，且它们需要相互通信。一个选项是建立一个异步通信，当生产者发起一个调用到消费者且等待回复。这个处理有它的优点和缺点。同步通信简单且更快能实现。同时同步通信很难处理消费者故障。我们需要思考什么时候和怎么合适地重试失败的请求，如何不被过多请求过载消费者服务且如何处理一个慢的消费者服务主机。另一个选项是引入一个新的组件帮助建立异步通信。生产者发送数据到那个组件且只有一个消费者之后获得这个数据。这样的组件被称为队列。且它是分布式的，因为数据存储在跨多个机器上。队列中消息只能发给一个消费者处理

功能性需求：

-   sendMessage(messageBody)
-   receiveMessage()

非功能性需求：

-   可扩展性（处理增长地负载，更多的队列和消息）
-   高可用（容忍硬件/网络故障）
-   高性能（对主要的操作有低延迟）
-   耐久性（一旦提交，数据不会丢失）

高层架构

首先，我们需要一个虚拟 IP，VIP 代表一个主机名（例如 myWebService.domain.com）解析为一个负载均衡系统。接下来，我们有一个负载均衡器。接着，我们有一个前端 Web 服务，其负责初始化请求处理，比如验证，鉴权等。队列元信息比如它的名字，创建日期和时间，拥有者和其他配置设置可存储在数据库中。在数据库之前有一个 Web 服务负责调用到数据库。且我们需要一个地方存储队列消息。这样让我们引入一个后端 Web 服务，负责消息持久化和处理

我们将解释负载均衡器如何获得高吞吐和有效性。当命中域名时，请求被传输到 DNS 注册的一个 VIP 中，VIP 被解析为一个负载均衡设备，其知道前端主机的信息。为处理高有效性，负载均衡器利用一个主和副节点的概念。主节点接受连接且服务请求当第二节点监控主节点。如果主节点不能接受连接，则副节点接管。对可扩展性，多 VIP 的概念（VIP 分区）可使用。在 DNS 中我们对服务赋值多个 A 记录到相同的 DNS 名。结果，请求分区跨几个加载均衡器。通过扩展负载均衡器到多个数据中心，我们改进了有效性和性能

前端 Web 服务：

-   一个轻量级 Web 服务
-   跨多个数据中心使用无状态服务

前端 Web 服务行为：

-   请求有效性
    
    确保请求中有所有需要的参数且参数值符合限制
-   验证/鉴权
    
    验证消息发送者是我们的分布式队列服务中注册过的用户。检查用户可以发送消息到队列
-   TLS（SSL）终止
    
    解密请求且传送解密的请求到后端服务。我们在这里做解密是因为在负载均衡上做负担很重。这个处理通常不被前端服务本身处理，而是交给一个独立的 HTTP 代理，其作为一个进程运行在相同的主机上
-   服务端加密
    
    因为我们想要在后端主机安全地存储消息，消息在前端服务一接受到之后就被加密。消息被以加密形式存储且前端解密它们当要发送回用户时
-   缓冲
    
    存储最活跃使用队列中的元数据信息。用户唯一信息
-   限速
    
    限制给定时间段内提交到一个给定操作的数量。保护 Web 服务不被请求过载。Leaky Bucket 算法是最著名的一个
-   请求分派
    
    负载所有涉及到发送请求到后端服务的活动，服务独立隔离，互不影响
-   请求去重
    
    缓存被用来存储之前看到的请求 ID 来避免重复
-   使用数据收集
    
    收集实时信息用来审查和用于发票

元数据服务

-   在前端和持久化存储之间的一个缓冲层
-   多读少写
-   强一致性存储更好但不是必要的

让我们看一下组织缓存簇的不同处理。第一个选项是当缓存相对小且我们可存储整个数据集在每个簇节点上。前端主机调用一个随机选择的元数据服务主机，因为所有缓存簇节点有相同的信息。第二个处理是分区数据为小块，称为切片。因为数据集太大且不能放入单个主机内存中。这样，我们存储每个这样的块数据在簇中单独的主机上。前端知道哪个切片存储的数据且直接调用该切片。第三个选项跟第二个相似。我们也分区数据为切片，但前端不知道在哪个切片存储，前端调用一个随机元数据服务主机且主机本身知道请求怎么转发。在第一个选项中，我们可在前端和元数据服务之间引入一个负载均衡器。在后两个选项中，元数据主机呈现一个一致哈希环

后端服务

-   我们如何和在哪里存储消息？
    
    后端主机的内存和本地磁盘
-   我们如何复制数据？
    
    复制到一组主机
-   前端如何选择一个后端主机来发送数据？前端如何知道从哪里获取数据？
    
    元数据服务


<a id="org2b6c6f4"></a>

# Share

[How to make an iOS App Secure?](https://www.shashankthakur.dev/2020/09/how-to-make-ios-app-secure.html)

这是移动的时代且在我们的智能手机上每天会有很多事情发生。感谢数百万个 app 帮助我们实现我们想要的任意事情。是否它在维持你的日程来管理金融信息，所有事情可用 app 完成。因为这些 app 能访问如此多机密信息，作为开发者当我们制作 app 时我们需要跟随最高的安全标准这样信息不会被人误访问

在日常中有超过十亿活跃设备。当开发 app 时我们要知道不同的安全练习

1.  启动 ATS
    
    强制 app 连接使用 HTTPS 和 TLS1.2

2.  SSL Cert Pinning
    
    这个技术非常高效地处理 MITM（中间人）攻击。SSL 工作于信任链。当 app 连接到服务器，客户端检查是否接收到的服务器 SSL 证书被任意 SSL 证书机构信任

3.  存储信息到 KeyChain 而不是 NSUserDefaults
    
    NSUserDefaults 里的信息没有加密，如果我们需要加密的形式，我们需要使用 KeyChain

4.  避免机密信息作为代码仓库的一部分
    
    任何机密信息不能是代码的一部分，我们应该使用配置文件或环境变量在构建应用程序时注入。一个好的选项是 Xcode 配置文件维护信息到一个特别的目标。一个用例是 API 键，我们不应该把 API 键作为代码的一部分。我们可以使用一个配置文件包含 API 键。这个文件可被内部放置于公司网络且可在 app 构建时读取且作为构建过程一部分注入

5.  Jailbreak 检测

    应用程序行为和逻辑容易被黑客用越狱设备容易获取。作为开发者，我们需要确保让黑客获得 app 内部细节变得困难。我们应该添加逻辑在 app 启动时检测越狱设备。且之后通知用户，可能会杀死 app

6.  只调试模式日志
    
    开发者使用调试消息来记录 app 行为。当 app 在开发时非常有用。当 app 在开发时我们趋于记录一些信息来帮助开发者构建特性。但，如果对于黑客它会暴露机密信息和 app 内部细节。为了确保我们在我们提交到 appStore 的版本没有日志消息我们用一个基本的检测让 app 只在调试模式启动
    
        #if DEBUG
        pring("log")
        #endif

7.  三方库的使用
    
    三方库有注入危险代码到代码库的风险。我们应该总是通过 Github 链接，license 和代码/安全 审查后集成
