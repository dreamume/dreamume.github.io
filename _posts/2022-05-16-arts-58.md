---
layout:     post
title:      "Weekly 058"
subtitle:   "Algorithm: Find First and Last Position of Element in Sorted Array; Review: Notes about Audio Technology; Tips: What's all the C Plus Fuss; Share:Notes about C++"
thumbnail-img: ""
date:       2022-05-16 20:00
author:     "dreamume"
tags: 		[it]
category:   it
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

# Table of Contents

1.  [Algorithm](#orgdf3f1f7)
2.  [Review](#org831f627)
    1.  [网络差怎么办？音频网络传输与抗弱网策略](#org0f49f86)
        1.  [实时音频传输](#org025a8db)
        2.  [弱网是如何形成的](#org037f122)
        3.  [抗弱网策略](#org2843d3b)
        4.  [总结](#org846d234)
    2.  [空间音频入门：如何实现“声临其境”？](#orga49181a)
        1.  [方位判断与双耳效应](#org8987f34)
        2.  [距离感和空间感](#orgd3ac85d)
        3.  [空间音频的采集](#orgd84f723)
        4.  [空间音频的播放](#orgd426339)
3.  [Tips](#org2981b7d)
4.  [Share](#orgcd416ff)
    1.  [性能测试的正确姿势：性能、时间和优化](#org560d0af)
        1.  [意外的测试结果](#orge4c6b2d)
        2.  [如何进行性能测试](#org00de10c)
        3.  [一个小测试框架](#orgc2fb9cb)
        4.  [浅谈优化的问题](#org73d1c11)
    2.  [快速分配和释放内存：内存池](#orge966327)
        1.  [一个测试用例](#orge7d064a)
        2.  [PMR 内存池](#org19419bd)
        3.  [自定义内存池](#orga2196c2)
        4.  [生命周期陷阱](#org5453218)


<a id="orgdf3f1f7"></a>

# Algorithm

Find First and Last Position of Element in Sorted Array <https://leetcode.com/problems/find-first-and-last-position-of-element-in-sorted-array>

<https://dreamume.medium.com/leetcode-34-find-first-and-last-position-of-element-in-sorted-array-e89345fb0782>


<a id="org831f627"></a>

# Review

搞定音频技术    冯建元


<a id="org0f49f86"></a>

## 网络差怎么办？音频网络传输与抗弱网策略

一般在弱网情况下，音频的体验可能表现为卡顿、杂音。如果情况严重可能会直接导致无法正常通话


<a id="org025a8db"></a>

### 实时音频传输

在实时音频交互的场景中，为了保证传输的实时性，一般使用基于 UDP 协议的 RTP 协议来传输音频数据。相较于 TCP 协议，UDP 提供了一种无需建立连接，就可以发送封装的 IP 数据包的方法

而 RTP 定义了我们音视频的数据包格式，其中包含了 RTP 版本号、包顺序编号等信息。而音频编码得到的压缩后的音频信息，就对应了数据包最后的 Audio Payload，也就是音频负载部分。我们可以通过下图来看看一个完整的音频数据包的组成形式
![img](../img/rtp_components.webp)


<a id="org037f122"></a>

### 弱网是如何形成的

弱网状态中有三个常见的问题：丢包（Packet Loss）、延迟（Latency）和抖动（Jitter）

1.  丢包

    在网络传输中，数据包会经过很多复杂的路径，有的是在物理传输中发生了丢失，有的是在服务器、路由转发时由于拥堵或等待时间过长被抛弃

2.  延迟和抖动

    从发送到接收经过的时间我们把它叫做延迟
    
    音频在发送的时候是按照时间顺序等间隔发送的，但是由于每个数据包经过的路径不同，从而到达目的地的延迟也不一样。这就导致有的时候很长时间都没有一个数据包到达，而有的时候几乎是同时来了好几个数据包。这就是我们常说的抖动。如果我们按照数据包到达的顺序去播放音频，那么音频播放可能是乱序的而发生杂音，也可能是没有数据可以播放，导致卡顿


<a id="org2843d3b"></a>

### 抗弱网策略

主要有网络丢包控制这一网络传输条件下的通用解决方法，和 NetEQ 这种音频独有的抗弱网策略这两块来解决弱网问题

1.  网络丢包控制

    简单地说，就是同一个包一次多发几个，只要不是都丢了就能至少收到一个包；又或者丢了包就再重传一个，只要速度够快还能赶上正常的播放时间就可以。这两种思想对应我们通常使用的前向纠错 FEC（Forward Error Correction）和自动重传请求 ARQ（Automatic Repeat-reQuest）这两个纠错算法
    
    FEC 是发送端通过信道编码和发送冗余信息，而接收端检测丢包，并且在不需要重传的前提下根据冗余信息恢复丢失的大部分数据包。即以更高的信道带宽作为恢复丢包的开销
    
    这里你需要注意的是：音频前向纠错遵循 RFC-2198 标准；而视频前向纠错遵循 RFC-5109 标准。音频由于数据包相比视频要小的多，可以直接用完整的音频包做冗余，而不是像视频用一个分辨率比较差的小数据包做冗余。如下图所示这就是 Simple-FEC 的原理
    ![img](../img/package_and_simple_fec.webp)
    我们看到上图中 FEC 就是每次发一个当前时间的数据包和一个上一时刻的冗余包，当其中一个数据包丢失时，我们可以用下一时刻的冗余包把数据恢复起来
    
    我们再看看另一种 FEC 的方法 [RS-FEC](https://datatracker.ietf.org/doc/html/rfc5510#page-15)，RS 码即里德 - 所罗门码（Reed-solomon Code）。这里我们结合下图来看一下
    ![img](../img/rs-fec.webp)
    我们假设每 m 个包（红色方块）进行一次 RS-FEC 编码得到 n 个冗余包（绿色方块）。冗余包加上原来的包，也就是我们在 m 个包的间隔时间里要发送 m+n 个包。RS-FEC 的特点是，我们只需要得到 m+n 个包中的任意 m 个包就可以把音频还原出来。在上图中，m = 4, n = 4，这样即使这 8 个包里连续丢了 4 个，也就是丢包率是 50%，都可以保证音频的流畅播放
    
    我们再来看看另一个常用的防丢包策略：ARQ。其实 ARQ 的原理非常简单。它就是采用使用确认信息（Acknowledgements Signal, ack），也就是接收端发回的确认信息，表征已正确接收数据包和超时时间。如果发送方在超时前没有收到确认信息 ack，那么发送端就会重传数据包，知道发送方收到确认信息 ack 或直到超过预先定义的重传次数
    
    可以看到相比 ARQ 的丢包恢复，由于 FEC 是连续发送的，且无需等待接收端回应，所以 FEC 在体验上的延时更小。但由于不管有没有丢包 FEC 都发送了冗余的数据包，所以它对信道带宽消耗较多。而相比 FEC 的丢包恢复，ARQ 因为要等待 ack 或者需要多次重传。因此，ARQ 延时较大，带宽利用率不高

2.  NetEQ

    其实为了解决弱网问题，在接收端音频解码时通常都有一套比较完整的抗丢包策略。实际上，很多音频编解码器或者开源实时音频框架中都自带了抗丢包策略，其中比较典型的是在 WebRTC 框架中的 NetEQ 模块。我们可以通过下图来了解一下
    ![img](../img/neteq_in_webrtc.webp)
    我们可以看到，NetEQ 主要包括两个模块：MCU（Micro Control Unit，微控制单元）和 DSP（Digital Signal Processing，信号处理单元）。我们知道由于网络传输的不稳定性，虽然我们有 FEC 和 ARQ，但由于延迟或者严重丢包导致的数据包乱序，或者数据包丢失，还是会经常发生的
    
    在 MCU 里的 Jitter Buffer（抖动缓存区）或者说 Packet Buffer（数据包缓存区）就是通过开辟一个比较大的缓冲区域，让一段时间内到来的数据包在 Jitter Buffer 里存储、排序。然后按照播放顺序把数据包交给 DSP 中的解码器进行解码
    
    在 DSP 模块中，由解码缓冲区得到的音频信号并不是直接交给播放设备播放的。而是需要根据网络状态、缓冲区未处理的数据包长度，以及等待播放的音频长度等参数，来决定使用 DSP 处理中的五种决策方法中的哪一种来处理音频数据。接下来我们就来看这五种策略：加速、慢速、正常、融合和丢包补偿背后决策的原理、实现方法和实际听感的效果是什么样的
    
    其实 NetEQ 中主要定义了四种收包的情况：
    
    1.  过去帧和当前帧都正确接收
        
        这种情况下只需要考虑网路抖动带来的数据包堆积和数据包接收不足的问题
        
        所谓数据包堆积，就是同一时间到达了多个数据包都在等待播放，而这个时候需要使用加速策略（accelerate），即对音频信号采用变速不变调的算法来缩短解码后音频的长度，从而实现快速播放
        
        相反的，如果在缓冲中的数据就快播放完了但新包还未送达，那么这时候就需要慢速的方法来把音频时长拉长。这里用到的同样是变速不变调的算法，即只改变音频的播放速度而不改变音频的音调
        
        WebRTC 中使用的是一种叫 WSOLA 的算法来实现的，这其实是音效算法中变调不变速算法的一种反向应用，更具体地我会在音效算法的一讲中详细解读
        
        那快慢放的听感是什么样的呢？在网络有抖动的时候，你可能会感觉对面说话，有的时候会快一点，有的时候会慢一点。这种快慢感在语音的时候可能不是那么容易察觉，这是因为人说话本来就有快有慢。但是在音乐的场景下，因为你对一首歌比较熟悉，所以快慢放就会更容易被察觉
    
    2.  当前帧发生丢包或者延迟
        
        如果当前帧发生了丢包或者延迟导致当前没有音频数据可以播放，这个时候就需要额外的 PLC（Package Loss Compensation，丢包补偿）模块来重建音频。你还记得我们在编解码器中讲的 LPC 算法吗？其实常见的 PLC 算法就是通过重建或者复用上一帧的 LPC 系数和残差来还愿这一帧的音频数据，从而实现丢包隐藏的
        
        慢放虽然也可以增加音频的长度但一个慢放系数比例确定后，慢放所能增加的音频长度也就固定了，所以一般慢放用于解决需预测时间比较短的音频的拉长。而 PLC 具有可扩展性，所以一般负责整个一帧或者多帧的，长时间的丢包补偿
    
    3.  连续多帧丢包
        
        连续多帧丢包用 PLC 就不行了，因为 PLC 补出来的音频很大程度上是上一帧音频的延长。如果长时间使用 PLC，声音就会变得失真，从而影响听感。所以如果出现连续多帧丢包，我们就会逐帧递减 PLC 补出音频的能量增益。这也就是为什么，长时间的丢包后的听感是声音逐渐变小直到没有声音，而不是有一个奇怪的声音一直在延续
    
    4.  前一帧丢失，当前帧正常
        
        最后这种情况前一帧可能存在 PLC 的补帧操作，那么新来的音频数据和上一帧就会出现不连续的情况，这里我们就会用到融合的操作。操作也比较简单，就是把当前帧的新数据和之前帧的音频做交叉淡化，让它们的连接处能平稳过度
        
        交叉淡化的步骤如下图所示，其实就是前一帧信号的末尾取一段逐步衰减至 0，然后让后一帧的前端数据从 0 开始逐步提升。然后把这两帧重叠部分相加就可以实现比较平滑的拼接了
        ![img](../img/audio_frame_cross_fade.webp)
        上图中橙色虚线表示交叉淡化用的淡化增益，第一第二行分别表示原始数据和交差淡化衰减后的曲线，最后一行是两帧重叠部分相加、拼接后得到的数据


<a id="org846d234"></a>

### 总结

NetEQ 中通过多个 Buffer 缓存以及快慢放的形式引入了延迟，从而提升了抗网络抖动的能力。然后通过 PLC 的方式解决丢包带来的音频卡顿。这与 FEC 和 ARQ 相比无需额外的带宽消耗，但是却增加了延迟

在实际中你可能需要针对自己的场景进行一些调整，比如说对于流畅通话比较重要的会议等场景，可以把 NetEQ 中的缓冲 Buffer 适量增大，这样可以进一步提升网络丢包的能力。但是 Buffer 也不能太大，这样会导致过多的延迟，从而影响通话效果

我们也可以在 NetEQ 中引入网络抖动情况的估计，比如在网络抖动严重的时候，动态增加 NetEQ 的 Jitter Buffer 的大小，而网络情况较好的时候减少一些 Jitter Buffer 的大小，从而降低延迟，这些都是可以改进的策略


<a id="orga49181a"></a>

## 空间音频入门：如何实现“声临其境”？

所谓空间音频的技术，就是把现实中这些对声音的感知，能够用空间音频采集设备和播放设备还原出来。空间音频涉及空间声学、空间声采集、空间声重放等细分领域，内容比较多。这里我会按照空间音频的基本原理以及空间音频的采集和播放，结合已有的解决方案，来给你讲一讲空间音频背后的原理和使用方法，从而让你能够快速步入空间音频这一音频“元宇宙”的入口


<a id="org8987f34"></a>

### 方位判断与双耳效应

我们先看这所谓的“方向感”是怎么产生的
![img](../img/extern_ear_receive_audio.webp)
我们可以通过上图看到人耳的耳廓在接收不同方向的音源时，会让声波以不同的路径传导至内耳。这样，不同方向的声波传输到内耳的时候，音色就会由于耳廓的形状而产生各向异性。除此之外，由于我们有两个耳朵，所以音源在不同方向时声波到达耳朵的时间也会不同，这一点我们可以结合下图来理解一下
![img](../img/two_ears_effect.webp)
其实很简单，如果音源在你的左侧，那么左耳会先接收到声波；相反如果音源在右侧，右耳会先收到声音。同时由于人的头部也会对声音的传播产生影响，如果音源在左侧，那么声波需要越过头部这个“障碍”才能传递到右耳，那么相对于左耳，音色和能量可能都会有所衰减。这其实就是空间音频里常说的“双耳效应”，即依靠双耳间的音量差、时间差和音色差来判别声音方位的效应


<a id="orgd3ac85d"></a>

### 距离感和空间感

距离感，给人的第一感觉是：如果这个声音的音量小，那么一定是因为它离我们比较远，而声音大则是距离近

而实际上声音的大小是相对的，比如可以音源离你很近但却只是低声细语，或者离得很远但用一个功率比较大的音箱，大声播放。所以用音量本身来判断声音的距离是不够的。实际上我们人耳对距离的感知是相对的。比如声音播放时音量由小变大，我们会感觉声音在靠近。或者同时播放两个吉他的声音，你会感觉声音小的是在远一些的位置

出了音量之外，还由于声波在空气传播中会产生衰减。而其中高频的声音衰减块、低频的衰减慢。那么同一个音量的声音，如果高频比较多，我们会觉得它离你更近一些。如下图所示，低频的声音可以传播得更远，而 8kHz 以上的声音如果超过 1 千米就很难被听到了
![img](../img/sound_wave_attenuate_curl_of_different_frequency.webp)
出了方向和距离，在之前讲回声消除的时候我们提到过混响的概念。其实混响也是我们感知声场空间大小的重要一环。简单地说，大房间的混响持续时间长，而小房间的混响持续时间短。我们能通过声音的混响来感知所在空间的大小。当然混响还和房间墙壁的材料、形状以及房间中障碍物的情况有关，所以我们对空间的感知相比方向和距离没有那么准确


<a id="orgd84f723"></a>

### 空间音频的采集

1.  入耳式麦克风于人工头

    很显然想要把人耳听到的声音完整的保留，我们可以采用入耳式麦克风，直接把左右耳道接收到的音频给录下来。或者如下图所示，可以使用人工头的方式，通过仿生模型，构造人头和耳廓、耳道等部位，然后通过人工头上的人工耳中内置的麦克风来采集空间音频
    ![img](../img/man_made_head.webp)
    入耳式麦克风和人工头采集的区别其实也显而易见的。如果你用入耳式麦克风采集的音频再用入耳式耳机播放，那么基本上可以做到完美还原。而如果是用人工头录制，那么由于耳廓的形状、头的形状等都和你自己有所不同，所以虽然可以做到很大程度上的空间还原，但和你自己实际到场景中去听，还是有一些差别的
    
    在实际使用中，每个人的耳朵、头的形状都不一样，但大体的形状和位置是相同的。所以利用人工头做音频录制在很多影视和游戏音频制作中会经常用到

2.  Ambisonics

    但拿人工头或者入耳式麦克风采集到的音频都还只是固定方向的立体声还原，且只能还原采集时人头朝向的声音。如果想把整个空间的声场都录下来，从而在回放的时候，你可以转动自己的头聆听任意方向的声音，那么就需要另一套叫做高保真立体声像复制（Ambisonics）的技术
    
    高保真度立体声像复制源于 20 世纪 70 年代牛津大学的一个三维空间声场重构技术研究。技术的核心是将远端中能听到的声音通过特制的麦克风录制，比如一阶 Ambisonics 麦克风（由四个完全相同的麦克风单元构成一个立方体阵列）的方式复制下来，我在下图展示了几个常见的一阶 Ambisonic 麦克风
    ![img](../img/ambisonic_microphones.webp)
    这里由一阶 Ambisonic 麦克风采集的原始数据我们叫 A-format，是无法直接播放的，需要按照多通道转码格式先转为 4 通道的 B-format。4 通道的 B-format 也叫作一阶 B-format。其中的四个通道分别称为 W、X、Y 和 Z。简单一点来理解，这四个方向分别代表了一个球形声场的中心、左右、前后和上下。B-format 的数据就可以用软件渲染成人意播放设备支持的格式，比如立体声、2.1、5.1 甚至 7.1
    
    低阶的 Ambisonics 麦克风可以还原一个比较小的声场，而如果是飞机场、大型演唱会等场景，则可能需要一个如下图所示的高阶的 Ambisonic 麦克风。我们可以看到阶数越多需要的麦克风的个数也就越多
    ![img](../img/advanced_ambisonic_microphones.webp)
    Ambisonics 技术在 AR、VR 等需要转动视角的场景里可以很好地还原整个声场的听感，所以被广泛应用


<a id="orgd426339"></a>

### 空间音频的播放

空间音频最常用的方式就是使用耳机播放。在空间音频的原理部分我们说过，要想感受空间音频最少需要一个双声道的音频播放，来让左右耳感知音量、音色、时间延迟等差异，从而形成空间感。同时，由于耳机的播放单元离人耳比较近，无需引入额外的声波传递带来听感的变化。所以用耳机来还原空间音频相对比较准确

但是耳机由于受限于结构和功率的限制，在低音部分的表现可能就不如音箱来得“震撼”。而且如果需要同时给多人播放体验空间音频，多声道的音箱系统会是我们的另一条可选的播放途径。多通道音箱系统的渲染格式经过多年的发展已经比较标准化了。常见的多通道音箱系统由 2.0、2.1、5.1、5.1.2、7.1、7.1.2 等等。那么它们分别代表什么含义呢？

其实这里我们可以把数字分成 A.B.C 三个部分。其中，A 代表由多少个环绕声扬声器（前置、中置和环绕）的数量；B 表示由多少个超低音音箱；C 代表顶部或向上发声扬声器的数量

举个例子，如下图所示，这是一个 Dolby 7.1.4 声道的全景音箱系统。其中环绕扬声器是其中长方体表示的左前、中置、右前、左、右、左后、右后共 7 个环绕扬声器。超低音音箱是左上方的正方形，它一般都是用于增强 200Hz 以下的超低频率的声音并且由于低频部分的声波波长较长，在房间内左右的感知不明显，所以方位上来说只需要放在房间中的任何位置即可。而在顶部的扬声器一般在听音位置也是如下图沙发上方均匀排布（黑色圆形），用于提供来自上方的声音渲染
![img](../img/dolby_7.1.4_audio_system.webp)
我们可以看到，不同的声音借由各个扬声器的位置和播放渲染可以实现比较好的声场还原。但是这种传统的家庭影院的布局并不能完美地还原声场。比如来自下方的声音就不能清晰重现，并且听音者只能在相对固定的位置（比如沙发）上才能获得正确的听感。所以这样的家庭影院看看电影还是不错的，但是玩一些 VR 游戏之类的就会显得声场渲染不足。

其实在普通的电影院也只是这种家庭影院的扩展，只是多一些环绕音箱让声音分辨力更强等等。从原理上来说音箱分布得越多、越密集，对声场得还原就越好。但显然这样所需的成本是巨大的，这其实也是多声道影院系统推出这么多年，推广一直受限的主要原因

我们在使用蓝牙耳机来听空间音频的时候，为什么有的时候会失去空间感呢？这里提示一下蓝牙耳机有很多协议，其中有的是单向高保真音频协议，例如 A2DP、LDAC 等；有的是双向低保真音频协议，例如 HFP（Hands-Free Profile）或 HSP（HeadSet Profile）


<a id="org2981b7d"></a>

# Tips

C++ 的喧哗？Bjarne Stroustrup 警告 C++ 的危险未来计划

<https://www.theregister.com/2018/06/18/bjarne_stroustrup_c_plus_plus/>

采访：2018年早期，Bjarne Stroustrup，C++ 的创造者，摩根斯坦利技术部门主任，哥伦比亚大学计算机科学访问教授，写了一封信邀请这些编程语言的演进监督来“Remember the Vasa!"


<a id="orgcd416ff"></a>

# Share

现代 C++ 实战（吴咏炜） 笔记


<a id="org560d0af"></a>

## 性能测试的正确姿势：性能、时间和优化


<a id="orge4c6b2d"></a>

### 意外的测试结果

假设你想测试一下，memset 究竟有没有性能优势。于是，你写下了下面这样的测试代码

    #include <cstdio>
    #include <string>
    #include <time.h>
    
    int main() {
        constexpr int LOOPS = 10000000;
        char buf[80];
        clock_t t1;
        clock_t t2;
    
        t1 = clock();
        for (int i = 0; i < LOOPS; ++i)
            memset(buf, 0, sizeof buf);
        t2 = clock();
        pirntf("%g\n", (t2 - t1) * 1.0 / CLOCK_PER_SEC);
    
        t1 = clock();
        for (int i = 0; i < LOOPS; ++i) {
            for (size_t j = 0; j < sizeof buf; ++j)
                buf[j] = 0;
        }
        t2 = clock();
        printf("%g\n", (t2 - t1) * 1.0 / CLOCK_PER_SEC);
    
        return 0;
    }

这里单线程下正确的行为可能到了多线程就有问题。但从性能测试的角度，即使单线程也一样会遇到鬼！编译器非常聪明，它看到了：你往内存里写数据了，又没有使用写到内存的数据；同时这是本地变量，你也没有把变量的引用或指针传到其他地方去。所以，外界不会观测到数据的改变。没人看到的东西，干吗需要存在？于是乎，编译器就把写内存的代码彻底优化没了

你模模糊糊想起来，volatile 关键字可以影响编译器优化。那加上这个关键字是不是有效呢？于是你把代码改成下面这个样子

    volatile char buf[80];
    // ...
    for (int i = 0; i < LOOPS; ++i)
      memset(const_cast<char *>(buf), 0, sizeof buf);

volatile 关键字确实阻止了编译器优化，但这回它反向影响了。volatile 在 C++ 里的语义是，严格按照代码的指示对内存进行读写：你写一次，编译器就产生相应读的代码 - 一个不多，一个不少。这就导致了对内存操作的性能劣化。通常，你只在进行内存映射的输入输出时才有这么用的必要

如果不用 volatile，那编译器至少在理论上是可以对上面的代码做出更好的优化的。我们把 buf 改成一个普通的全局变量，就能测到一个更接近真实的效果了。我们可以看到，GCC 和 Clang 都做出了更好的优化，对 memset 和循环清零产生了完全相同的代码。GCC 在 Core i7 架构（-march=corei7）上产生的汇编代码如下

    pxor xmm0, xmm0
    movaps XMMWORD PTR buf[rip], xmm0
    movaps XMMWORD PTR buf[rip + 16], xmm0
    movaps XMMWORD PTR buf[rip + 32], xmm0
    movaps XMMWORD PTR buf[rip + 48], xmm0
    movaps XMMWORD PTR buf[rip + 64], xmm0

也就是说，编译器洞察了你要做的事情是往 buf 里写入 80 个零，因而采取了最高效的方式，一次写 16 个零，连写五次，根本就没有循环了


<a id="org00de10c"></a>

### 如何进行性能测试

1.  内存屏障问题

    使用全局变量并不意味着我们一定就能测到真实数据。以上面这个测试为例，虽然编译器看到我们往全局变量写入，就一定不可能把写入完全忽略掉，但它完全可能会做一些写入的合并。事实上，实测下来 Clang 就做了写入的合并，因此测试的结果数据看起来比 GCC 和 MSVC 要漂亮很多。从测试上面两种写法的区别上讲，问题还不算大，但如果我们想拿这个数据来计算代码的性能数据的话，那就要了命了
    
    一种可能的解法是加入内存屏障，告诉编译器到现在为止的内存修改都得给我完成了。全局锁就是一种通用的内存屏障，但在上面的代码里加入全局锁的话，加解锁的开销就会完全掩盖我们要测试部分的开销了。每种处理器架构都有自己的内存屏障指令，这比 C++ 或操作系统的锁要轻量一点，但对于我们上面的测试来讲，仍然是重了（约 10 倍的性能下降）。每一种编译器，基本上也都有非标准的轻量级内存屏障指令，只影响编译器优化，而不影响 CPU 的处理性能
    
    最后一种方式看起来最有希望，但遗憾的是，在我们上面的例子里，加入内存屏障本身会影响 GCC 产生的代码。仅针对目前的代码，我们可以写出下面这样一个内存屏障的函数
    
        #ifdef _MSC_VER
        #include <intrin.h>
        #endif
        
        inline void memory_fence() {
        #ifdef _MSC_VER
            _ReadWriteBarrier();
        #elif defined(__clang__)
            __asm__ __volatile__("" ::: "memory");
        #endif
        }
    
    然后我们在测试代码后调用这个函数，确保对内存的写入会生效。注意我们仍需使用全局变量作为写入目标才行
    
    这种解法的问题是，它实在太脆弱了。从原理上来讲，它能不能工作并没有任何人可以保证。对于一个新的编译器，代码很可能会无效；对于当前工作的编译器的一个新版本，代码也可能会变为无效
    
    目前最可靠也最跨平台的解决方案仍然是用锁。如果想使用锁，我们需要有一种比 clocl() 精度高得多的测量时间的办法
    
    Linux:
    
    <table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
    
    
    <colgroup>
    <col  class="org-left" />
    
    <col  class="org-right" />
    
    <col  class="org-left" />
    </colgroup>
    <thead>
    <tr>
    <th scope="col" class="org-left">函数</th>
    <th scope="col" class="org-right">精度（微秒）</th>
    <th scope="col" class="org-left">耗时（时钟周期）</th>
    </tr>
    </thead>
    
    <tbody>
    <tr>
    <td class="org-left">clock</td>
    <td class="org-right">1</td>
    <td class="org-left">~1800</td>
    </tr>
    
    
    <tr>
    <td class="org-left">gettimeofday</td>
    <td class="org-right">1</td>
    <td class="org-left">~69</td>
    </tr>
    
    
    <tr>
    <td class="org-left">clock_gettime</td>
    <td class="org-right">0.0265(38)</td>
    <td class="org-left">~67</td>
    </tr>
    
    
    <tr>
    <td class="org-left">std::chrono::system_lock</td>
    <td class="org-right">0.0274(38)</td>
    <td class="org-left">~68</td>
    </tr>
    
    
    <tr>
    <td class="org-left">std::chrono::steady_clock</td>
    <td class="org-right">0.0272(28)</td>
    <td class="org-left">~68</td>
    </tr>
    
    
    <tr>
    <td class="org-left">std::chrono::high_resolution_clock</td>
    <td class="org-right">0.0275(20)</td>
    <td class="org-left">~69</td>
    </tr>
    
    
    <tr>
    <td class="org-left">rdtsc</td>
    <td class="org-right">0.00965(48)</td>
    <td class="org-left">~24</td>
    </tr>
    </tbody>
    </table>
    
    Windows:
    
    <table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
    
    
    <colgroup>
    <col  class="org-left" />
    
    <col  class="org-right" />
    
    <col  class="org-left" />
    </colgroup>
    <thead>
    <tr>
    <th scope="col" class="org-left">函数</th>
    <th scope="col" class="org-right">精度（微秒）</th>
    <th scope="col" class="org-left">耗时（时钟周期）</th>
    </tr>
    </thead>
    
    <tbody>
    <tr>
    <td class="org-left">clock</td>
    <td class="org-right">1（毫秒）</td>
    <td class="org-left">~160</td>
    </tr>
    
    
    <tr>
    <td class="org-left">GetTickCout</td>
    <td class="org-right">15.63(49)（毫秒）</td>
    <td class="org-left">~10</td>
    </tr>
    
    
    <tr>
    <td class="org-left">GetPerformanceCounter</td>
    <td class="org-right">0.1</td>
    <td class="org-left">~61</td>
    </tr>
    
    
    <tr>
    <td class="org-left">GetSystemTimeAsFileTime</td>
    <td class="org-right">15.63(49)（毫秒）</td>
    <td class="org-left">~20</td>
    </tr>
    
    
    <tr>
    <td class="org-left">GetSystemTimePreciseAsFileTime</td>
    <td class="org-right">0.1</td>
    <td class="org-left">~100</td>
    </tr>
    
    
    <tr>
    <td class="org-left">std::chrono::system_lock</td>
    <td class="org-right">0.1</td>
    <td class="org-left">~100</td>
    </tr>
    
    
    <tr>
    <td class="org-left">std::chrono::steady_clock</td>
    <td class="org-right">0.1</td>
    <td class="org-left">~160</td>
    </tr>
    
    
    <tr>
    <td class="org-left">std::chrono::high_resolution_clock</td>
    <td class="org-right">0.1</td>
    <td class="org-left">~160</td>
    </tr>
    
    
    <tr>
    <td class="org-left">rdtsc</td>
    <td class="org-right">0.00973(93)</td>
    <td class="org-left">~25</td>
    </tr>
    </tbody>
    </table>
    
    精度的测量是取当函数返回的数值变化时的差值。当连续调用某一个计时函数时，它返回的结果是可能不变的。当它变化时，变化的数值就是它的测时精度。表中展示的就是这些精度测量结果的平均值（及方差，如果测试结果不完全一样的话）
    
    精度受 API 设计的影响，也受函数实现的影响。比如，Windows 上定义 CLOCK_PER_SEC 为 1000，显然 clock() 也就不可能获得高于一毫秒的精度了。C++11 的三种时钟从目前实现的接口上来看都允许实现一纳秒的精度，但实际精度则要远远低于一纳秒
    
    测试结果当然跟具体的硬件也可能有关系，但至少这里可以看到一些基本的共性：
    
    -   首先，clock() 函数不是个好选择，它的精度可能很差，本身耗时也可能会比较长
    -   其次，C++11 带来的三种时钟不管是精度还是自身开销都还算不错。既然其它方面没有区别，我们就选择使用能提供稳定增长保证的 steady\_clock（system\_clock 是不稳定的，系统时间被调整时，时钟返回的数值也会变化；high\_resolution_clock 的稳定性在标准中没有进行规定）[[1]​](https://en.cppreference.com/w/cpp/chrono#Clocks)
    -   最后，如果时间戳计数器（Time Stamp Counter[[2]​](https://en.wikipedia.org/wiki/Time_Stamp_Counter)） 可用的话，它能提供最高的精度和最短的耗时。它是处理器上的硬件计数器，精度高，速度快，在多核系统上也能提供正确的读数；但在多 CPU 插槽的系统上则不一定能提供相应的保证，因而在那种情况下可能需要把测试程序绑定到某个核上运行
    
    rdtsc 返回的数值单位是时钟周期数（但频率可能跟处理器的实际运行频率不同）。上表中测量各个函数的耗时用的就是 rdtsc
    
    我目前在 [代码库](https://github.com/adah1972/geek_time_cpp) 里加入了 rdtsc.h 文件。它的实现就是优先使用 x86 和 x86-64 平台提供的 rdtsc 的实现，在找不到时转而使用 stead_clock 作为替代
    
    额外提一句，我这边讲的性能测试是微观层面的测试，即所谓的 microbenchmarking，一般以函数为单位。这种测试是单线程的，需要干扰尽可能少。可能的干扰有：
    
    -   其他的应用程序 - 应尽可能关闭其他应用，尤其是会耗 CPU 的
    -   处理器的自动频率变化 - 最好关闭这类功能，如 Intel 的 Turbo Boost
    -   不同性能核之间的迁移 - 如果你的测试系统上有所谓的大小核，而你又没办法把程序绑定到某个核上面的话，那这样的系统不适合用来做微观层面的性能测试

2.  通用测试方法

    下面我们讨论一种我个人经常使用的通用的性能测试方法。由于编译器的很多优化机制并不能由代码来控制，这也只能算是一种最佳实践而已。根据你的特定平台，也许你可以找出更好的测试方法
    
    我的基本方法是：
    
    -   把待测的代码放到一个函数里，这样容易消除一些其它干扰
    -   可选地，把这个函数用 \__attribute\__((oninline))[[3]​](https://gcc.gnu.org/onlinedocs/gcc-11.2.0/gcc/Common-Function-Attributes.html) 或 \__declspec(noinline)[[4]​](https://docs.microsoft.com/en-us/cpp/cpp/noinline?view=msvc-170) 标注为不要内联
    -   确保有一个依赖函数直线结果的数值会被写到某个全局变量里。根据代码的规模和组织，可以直接在这个函数里写入，或者通过外部传入的一个全局变量的指针或引用来写入
    -   在函数的开头和结尾测量时间，并把测得的时长累加到某个地方
    -   在循环里反复调用被测函数，并在每次调用函数前后进行加解锁，产生内存屏障
    
    比如，memset 的测试代码可能就会变成这个样子
    
        char buf[80];
        uint64_t memset_duration;
        
        std::mutex mutex;
        
        void test_memset() {
            uint64_t t1 = rdtsc();
            memset(buf, 0, sizeof buf);
            uint64_t t2 = rdtsc();
            memset_duration += (t2 - t1);
        }
        
        int main() {
            constexpr int LOOPS = 10000000;
            for (int i = 0; i < LOOPS; ++i) {
                std::lock_guard guard{mutex};
                test_memset();
            }
        
            printf("%g\n", memset_duration * 1.0 / LOOPS);
        }
    
    使用这种方法，我们确实可以验证出在 GCC 和 Clang 下，两种清零方法在缓冲区大小已知的情况下可以获得相同的性能（如果大小要运行时才能决定，那就是另外一个需要单独测试的问题了）


<a id="orgc2fb9cb"></a>

### 一个小测试框架

利用 RAII，我们可以使用一个框架把代码再整理一下，使得测试更加简单和自动。这个框架毕竟简单，设计和实现我就不讲了

对于当前的例子，首先我们需要声明两个待测函数的索引

    enum profiled_functions {
        PF_TEST_MEMSET,
        PF_TEST_PLAIN_LOOP,
    };

然后，我们需要声明函数索引和函数名的关系：

    name_mapper name_map[] = {
        {PF_TEST_MEMSET, "test_memset"},
        {PF_TEST_PLAIN_LOOP, "test_plain_loop"},
        {-1, nullptr}};

对于待测函数，我们需要在函数开头插入一行代码，表示要对这个函数进行性能测试（利用一个 RAII 对象）：

    void test_memset() {
        PROFILE_CECK(PF_TEST_MEMSET);
        memset(buf, 0, sizeof buf);
    }

完整代码请参考 GitHub 上的 [代码库](https://github.com/adah1972/geek_time_cpp)。如果想检查不同架构下的性能差异的话，可以在 cmake 命令行上指定编译器和附加参数，如：

    CXX='g++ -march=corei7' cmake ...

此外，需要说明一下，跟 assert 类似，PROFILE\_CHECK 宏在 NDEBUG 宏被定义时就不生效了。所以，上面的输出在使用了 cmake -DCMAKE\_BUILD_TYPE=Release ... 时就不会有了


<a id="org73d1c11"></a>

### 浅谈优化的问题

今天提到的测试困难，很大程度上都是 C++ 编译器的优化造成的。事实上，C++ 里很多未定义行为之所以成为未定义行为，也是跟性能有关的。为了追求性能，C++ 编译器是可谓无所不用其极。有些人觉得编译器忽略了人的意图，感到很不爽，但事实是，C++ 编译器在优化方面确实比大部分程序员做得更好。这也是现在基本上没人写汇编的原因 - 即使不考虑可移植性，在某一特定平台上要写出超出 C++ 编译器水平的汇编代码，也已经越来越困难了

但这种优化，虽然常常对程序有好处，也常常是违背程序员的直觉的。我这里另外举两个简单的例子，来说明一下为什么 C++ 编译器需要违反程序员的直觉

1.  优化和未定义行为

    假如我们有一个 int 类型的变量 x，那 x \* 2 / 2 的结果是几？
    
    如果 C++ 把有符号整数运算溢出的结果定义为补码的内存表示，也就是说，32 位正整数 0x40'00'00'00（$ 2^{30} $）乘以 2 的结果就是 0x80'00'00'00（$ -2^{31} $ ），再除以 2 的话，我们就不能得回原先的数值，而是得到了 0xC0'00'00'00（ $ -2^{30} $）。这样的话，x \* 2 / 2 就不能优化为 x
    
    那能不能使用异常呢？也不行。跟除零不一样，整数运算溢出不会产生硬件中断。而如果我们在每条加法、减法、乘法、除法（对，除法也可能溢出 - INT\_MIN / -1 就会）上都加入指令来检查是否发生溢出、并在发生溢出时报告异常的话，性能的退步是不可接受的 [[5]​](https://www.cs.utah.edu/~regehr/papers/overflow12.pdf)
    
    所以，C++ 的处理方式就是，规定有符号整数运算溢出为未定义行为 [[6]​](https://en.cppreference.com/w/cpp/language/ub) ，即程序员需要保证这种情况不会发生，否则后果自负。这在允许编译器把 x \* 2 / 2 优化成 x 的同时，也意味着，下面这样的代码返回的结果可能会跟程序员预想的不同（参见 [[7]​](https://godbolt.org/z/Ex5ad6vM9)）：
    
        bool test(int n) {
            return (n + 1) == INT_MIN;
        }
    
    你想的是，如果 n + 1 溢出了，应该会得到 INT_MIN 这个特殊的结果。但编译器可以认为溢出是永远不会发生的（因为正确的程序里不应该有未定义行为），因此可以直接返回 false。- 这也是实际可以在 GCC 和 Clang 上测到的结果

2.  优化和执行顺序

    假设我们有三个全局 int 变量 x、y 和 a，然后我们执行下面的代码
    
        x = a;
        y = 2;
    
    下面是某些编译器实际产生的汇编代码（参见 [[8]​](https://godbolt.org/z/zsfvsf63E)）：
    
        mov exa, DWORD PTR a
        mov DWORD PTR y, 2
        mov DOWRD PTR x, eax
    
    因为优化，读入 a 的数值到 eax 寄存器里，跟写入 2 到 y里是两个不相关操作，可以同时执行。这样的代码，比起完全按程序员指定的执行顺序产生的代码，可望得到更高的性能


<a id="orge966327"></a>

## 快速分配和释放内存：内存池


<a id="orge7d064a"></a>

### 一个测试用例

下面是一些你可能想使用内存池的理由：

-   希望减少内存分配和释放的时间开销 - 更快的分配和释放
-   希望减少内存分配和释放的空间开销 - 更少的总体内存使用

下面则是一些反对使用内存池的理由：

-   你的通用内存分配器可能已经足够快了
-   使用内存池可能导致操作系统更难回收你已经不再需要的内存
-   使用内存池可能使得你的对象较难跟其他对象进行交互

如果你想要进行某个操作的性能测试，你就需要某种“典型场景“。作为例子，我这儿拿一个掺入了随机操作的过程当作测试场景。具体来说，我做的事情是

1.  产生随机数
2.  把这些随机数插入到一个 unordered_set 中，测量所需的时间
3.  把这些随机数从这个 unordered_set 里逐个删除，测量所需的时间
4.  再把这些随机数重新插入到 unordered_set 中，测量所需的时间

这虽然不是一个完美的例子，但确实可以让我们观察到内存池的作用。如果你有真实的场景，也可以借鉴这种方式来进行测试

    using TestType = unordered_set<int>;
    TestType s;

产生随机数的代码略复杂一点：

    mt19937 engine;
    uniform_int_distribution<int> dist;
    array<int, LEN> rand_nums{};
    for (int& num: rand_nums) num = dist(engine);

我们希望得到跨平台的稳定测试结果，因此指定了一个名声不错的伪随机数引擎 mt19937（否则默认的伪随机数引擎 default\_random\_engine 也没什么问题）。我们只需要一个简单的随机均匀分布，因而使用了默认构造的 uniform\_int\_distribution，不给出随机数的范围，来产生所以合法证书范围内的随机数。然后，我们在长度为 LEN 的数组中，每一项（注意此处必须使用引用的方式来范围遍历 rand_nums）都写入一个随机的整数。由于我们没有对随机数引擎使用真正随机的种子来初始化，这些随机数每次都是相同的，可以保证测试的稳定性

初始插入操作就简单了，只是把数组 rand_nums 里的每一项插入到 s 里。由于 s 这个变量的操作实在有点复杂，不管它是全局变量还是本地变量，编译器都不太可能把这些操作优化掉了。我们这个测试可以简单地测量总体耗时：

    t1 = rdtsc();
    for (int num: rand_nums) s.insert(num);
    t2 = rdtsc();

删除操作也类似

    t1 = rdtsc();
    for (int num: rand_nums) s.erase(num);
    t2 = rdtsc();

最后，我们再重复一遍插入的过程，看看重新插入的性能有没有变化。完整的测试代码可以看一下 [代码库](https://github.com/adah1972/geek_time_cpp)

运行测试代码，我们可以看到再次插入的性能比第一次高，在 Linux 上尤其明显

事实上，这还只是使用默认的内存分配器的结果。使用不同的内存分配器也能获得不同的效果。比如，在 Linux 上使用 [tcmalloc](https://github.com/gperftools/gperftools) 来取代默认的分配器 [[1]​](https://www.gnu.org/software/libc/manual/html_node/The-GNU-Allocator.html)，我们可以得到更好的测试结果

取决于你使用的平台的内存分配器的性能，也取决于你是否需要跨平台地得到更好的内存分配性能，内存池也许对你很有用，也许对你用处不大


<a id="org19419bd"></a>

### PMR 内存池

有了测试用例，我们可以验证一下多态分配器里提供的内存池的作用了。我们只需要对测试用例做一下小修改，把 TestType 相关的两行改成下面这样子就行

    using TestType = pmr::unordered_set<int>;
    pmr::unsynchronized_pool_resource res;
    pmr::polymorphic_allocator<int> a{&res};
    TestType s(a);

在 MacOS 和 Windows 上，我看到了更大的、全方位的性能提升。对于跨平台应用，这样的内存池确实会有效果

注意，我上面使用的是无多线程同步的 unsynchronized\_pool\_resource。有多线程同步的内存池就是另外一个故事了。在 Linux 上，性能反而会有下降；而在其他平台上，性能提升也很不明显。 - 一般而言，对于多线程的处理，通用内存分配器已经做了充足的优化，性能上可能反而会超出一般简单实现的内存池。内存池通常应该在单线程或线程本地（thread_local）的场景使用，至少从执行时间的角度来讲是如此


<a id="orga2196c2"></a>

### 自定义内存池

利用同一类型的对象的大小完全相同这一特性，可以实现一个高度优化的内存池。只是利用类特定的分配和释放函数，使用场景会比较受限。下面我会描述利用这个思路实现一个内存池，既可以用在类特定的分配和释放函数里，也可以用在容器的分配器里

1.  基本策略

    作为内存池，最基本的要求就是减少向系统的内存分配器请求内存的次数。因此，我们希望单次内存分配就获得大块的内存（chunk），然后分割开给各个对象使用。这样的内存块，通常是某个特定大小的整数倍
    
    下一步，我们有两种不同的做法：
    
    1.  任何要求某个大小（或某个大小范围）的内存分配请求都到某一个内存池里分配和释放
    2.  任何要求某个特定类型的对象的内存分配请求都到某一个内存池里分配和释放
    
    第一种做法跟 SGI STL 差不多，而第二种做法是 C++ 的内存分配机制给我们的额外优化机会。两种做法各有一些优缺点，而我目前是采取了第二种做法，主要考虑下面这些因素：
    
    -   不同类型的对象使用不同的内存池，即使它们的大小相同。在很多场景下，把同一类型的对象放在一起，程序会有更好的局域性
    -   通过对象类型可以得出对象大小，但反过来则不可以。换句话说，按我们目前的方式，你可以把方案退化成只使用对象大小，因而讲解目前这种方式更具有通用性
    
    我做的另外一个选择是在大部分时间里不返回内存给内存分配器。原因是：
    
    -   返回内存给内存分配器反而更容易导致内存碎片，导致后续内存不足或消耗更大
    -   返回内存给内存分配器，通常内存分配器也没法返回给操作系统（因为内存碎片的原因），因此并不能减少程序的运行期内存开销
    -   不返回内存给内存分配器的话，实现简单，代码更小、更快
    
    我的一些实验表明，内存池也很难决定什么时候返回内存给内存分配器。如果某个内存块（chunk）全空就返回的话，程序向内存分配器请求内存的次数会明显增加。目前我能想到的唯一好处，是程序的对象数量会有明显的波动的时候：在某个时刻，又会产生大量的 B 对象，然后释放掉。仅在这种情况下，我的不返回选择会增加程序的最大内存开销。目前我就暂不考虑这种特殊场景了

2.  对象内存池

    根据上面的讨论，我们需要有一个内存块的数据结构，也需要决定一个内存块里放多少个对象。我们采用一个可特化的参数来决定后者：
    
        template <typenmae T> inline constexpr size_t memory_chunk_size = 64;
    
    也就是说，memory\_chunk\_size 默认大小是 64，但你可以针对某一特定类型来进行特化，改变其大小。比如，你想针对你的某一特定 Obj 类型把大小改成 32，你可以写
    
        template <> inline constexpr size_t memory_chunk_size<Obj> = 32;
    
    当然，一般情况下你没必要这么做。在大部分需要内存池的场景，默认大小已经工作得挺好了
    
    然后，我们需要定义一个数据结构，可以存放某种对象，也可以把内存块串成一个链表。显然，我们可以使用一个 union:
    
        union node {
            T data;
            node* next;
        };
    
    直接使用 T 类型的好处是我们可以自然地使用 T 类型的对齐特征，而不需要使用 alignas 之类的麻烦方式。不过，我们也有一些小复杂性需要解决：当 T 是一个带有非平凡构造函数和析构函数的对象时，上面的代码编译会有问题，因为编译器不知道在构造和析构时到底该怎么办了。我们只用这个结点来管理内存，因此我们声明空的构造函数和析构函数就好（注意，此处不能使用 = default）。此外，这样的内存结点显然也不应该进行复制，因此，我们最好要禁用拷贝构造函数和拷贝赋值运算符
    
        union node {
            T data;
            node* next;
            node() {}
            ~node() {}
            node(const node&) = delete;
            node& operator=(const node&) = delete;
        };
    
    然后，我们就可以定义出内存块了：
    
        template <typename T> class memory_chunk {
        public:
            union node {
                // ...
            };
            memory_chunk(memory_chunk* next_chunk);
            node *get_free_nodes() {
                return storage_.data();
            }
            memory_chunk* get_next() const {
                return next_chunk_;
            }
        private:
            memory_chunk* next_chunk_{};
            array<node, memory_chunk_size<T>> storage_;
        };
    
    内存块就是结点的数组，加上指向下一个内存块的指针，来把内存块串成一个链表。我们通过构造函数来初始化内存块
    
        template <typename T> memory_chunk<T>::memory_chunk(memory_chunk* next_chunk) : 
            next_chunk_(next_chunk) {
            for (size_t i = 0; i < storage_.size() - 1; ++i) 
                storage_[i].next = &storage_[i + 1];
            storage_[storage_.size() - 1].next = nullptr;
        }
    
    “下一个”内存块的指针由外部传入。对于结点的数组，我们使每个结点的 next 指针指向下一项；把内存块串成一个链表，供后面内存池来使用
    
    有了这些原料，我们的内存池就可以很方便地写出来了。类的定义如下
    
        template <typename T> class memory_pool {
        public:
            using ndoe = typename memory_chunk<T>::node;
            memory_pool() = default;
            memory_pool(const memory_pool&) = delete;
            memory_pool& operator=(const memory_pool&) = delete;
            ~memory_pool();
            T* allocate();
            void deallocate(T* ptr);
        private:
            node* free_list_{};
            memory_chunk<T>* chunk_list_{};
        };
    
    可以看到，内存池对象只有两个成员变量，free\_list\_ 和 chunk\_list\_，及三个成员函数，析构函数、allocate 和 deallocate。free\_list\_ 是空闲结点的链表，chunk\_list\_ 是所有内存块的链表。而在三个成员函数里，析构函数的意义是负责释放所有的内存块：
    
        template <typename T> memory_pool<T>::~memory_pool() {
            while (chunk_list_) {
                memory_chunk<T>* chunk = chunk_list_;
                chunk_list_ = chunk_list_->get_next();
                delete chunk;
            }
        }
    
    allocate 负责内存的分配
    
        template <typename T> T* memory_pool<T>::allocate() {
            if (free_list_ == nullptr) {
                chunk_list_ = new memory_chunk<T>(chunk_list_);
                free_list_ = chunk_list_->get_free_nodes();
            }
        
            T* result = &free_list_->data;
            free_list_ = free_list_->next;
            return result;
        }
    
    我们首先检查空闲列表 free\_list\_是否为空，为空则说明内存池里已经没有内存供对象使用，因此我们需要新申请一个内存块，然后让 chunk\_list\_ 指向这个新内存块，并让 free\_list\_ 指向其首项。随后，分配内存只是简单地从结点链表上摘下一项，并调整链表的首项指针
    
    deallocate 当然就是负责内存的释放
    
        template <typename T> void memory_pool<T>::deallocate(T* ptr) {
            auto free_item = reinterpret_cast<node*>(ptr);
            free_item->next = free_list_;
            free_list_ = free_item;
        }
    
    顺便说一句，对于调整链表这样的操作，标准库提供的 std::exchange 工具可以让代码更加简洁。比如，allocate 最后三条语句可以缩成一条：return &exchange(free\_list\_, free_list\_->next)->data;

3.  内存池应用：类特定的分配和释放函数

    虽然类特定的分配和释放函数已经不那么经常使用，我们还是可以看一下如何把内存池用到这一最简单的应用场景中。这也可以让我们测一下这种极端情况下的内存池收益
    
    之前提过，对于某一个类 Obj，我们要使用类特定的分配和释放函数，只需在其中声明这样两个成员函数
    
        class Obj {
            // ...
            void *operator new(size_t size);
            void operator delete(void* ptr) noexcept;
        };
    
    这里我省去了声明前的 static，这是允许的，效果相同（不管写不写 static，这两个函数都是静态的）。我们可以在这个类的实现文件（非头文件）里加入下面的内容即可使用内存池：
    
        memory_pool<Obj> obj_pool;
        
        void* Obj::operator new(size_t size) {
            assert(size == sizeof(Obj));
            return obj_pool.allocate();
        }
        
        void Obj::operator delete(void *ptr) noexcept {
            obj_pool.deallocate(static_cast<Obj *>(ptr));
        }
    
    对于这样的对象，及没有类特定的分配和释放函数的对象，分别做大量的 new 和 delete 操作，我在 Linux（默认分配和释放性能最好的主流平台）上得到，不使用内存池时平时每次分配和释放耗时 107 个时钟周期，使用内存池则降为 8 个时钟周期
    
    如果使用 tcmalloc，区别就小一点，不使用内存池也只要 27 个时钟周期

4.  内存池应用：分配器

    上面的测试可以让我们看到内存池带来的收益会有多大，但手工使用 new 和 delete 早就已经不是推荐的做法了。最常见的情况，我们需要把对象放在容器里面。因此，我们需要让分配器支持内存池
    
    除了我们定义分配器需要的那些必要定义外，我们需要定义的核心成员函数是 allocate 和 deallocate。实现的示意如下：
    
        template <typename T> memory_pool<T>& get_memory_pool() {
            thread_local memory_pool<T> pool;
            return pool;
        }
        
        template <typename T, typename Base = allocator<T>> struct pooled_allocator : private Base {
            // ...
            T* allocate(size_t n) {
                if (n == 1) return get_memory_pool<T>().allocate();
                else return Base::allocate(n);
            }
        
            void deallocate(T* p, size_t n) {
                if (n == 1) return get_memory_pool<T>().deallocate();
                else Base::deallocate(p, n);
            }
        };
    
    也就是说，对于每一种特定类型 T，我们都有一个专属的线程本地内存池。这个内存池会在首次使用被创建，在线程退出时被销毁
    
    在 allocate 和 deallocate 函数里，我们首先检查需要分配和释放的对象个数。当前的实现不能处理超过单个对象大小的分配和释放，因此，这样的请求会直接转到基类的内存分配器进行处理，默认情况下是系统的 std::allocator，它会使用 operator new 和 operator delete 来进行分配和释放。我们仅针对单个对象的内存分配和释放使用线程本地内存池，因此这个分配器适合 list、map、set 这样的对元素单独分配内存的容器，而不适合 vector、deque 这样的批量分配内存的容器。- 后者实际上也基本没有使用内存池的必要了
    
    使用这个内存池很简单，把容器的 Allocator 模板参数设成目前实现的 pooled\_allocator 即可。使用之前的测试，我们需要把 TestType 定义成下面的形式
    
        using TestType = unordered_set<int, hash<int>, equal_to<int>, pooled_allocator<int>>;
    
    由于 Allocator 是最后一个参数，我们必须把之前类模板的默认模板参数也手工补上，也就是 hash<int> 和 equal_to<int> 这两个


<a id="org5453218"></a>

### 生命周期陷阱

如果你原封不动按我目前给出的代码来自己实现一遍的话，你很可能看到程序在退出时挂起或崩溃。问题是这样发生的

1.  我们有一个全局对象，在构造时会把它的析构函数调用挂到程序退出时需要执行的代码中
2.  在这个全局对象首次需要内存时，我们会初始化内存池的实例。同时，它的析构函数会挂到线程退出需要执行的代码中。注意这比第 1 步要晚
3.  内存池析构会发生在全局对象析构之前（即使它们都是全局对象或者都是线程本地对象，也一定是后构造的先析构），它会释放所有的内存
4.  在全局对象析构时，如果有任何读写之前分配的堆上内存的操作，都是未定义行为

那么问题如何解决呢？我们可以选择以下几种方式：

-   确保内存池的构造先于全局对象的构造。把全局对象改成 thread\_local 是一件简单的事（或者如果我们只需要单线程操作的话，可以把 get\_memory\_pool 里的 thread\_local 改成 static），但问题是，内存池实例的类型是实现定义的，很难预料。对于我们的 unordered\_set<int, ...>，真正需要实例化的内存池类型可能是 pooled\_allocator<std::\__detail::\_Hash_node<int, false>>，并且会随编译器不同而不同
-   在线程退出时不释放内存。问题是，如果我们重复起停线程的话，就会有内存泄漏了。只有在我们起的线程数量固定的情况下，这种方法才可行
-   不使用全局对象或线程本地对象，而是只使用本地对象。这当然对程序是一种限制

很遗憾，似乎真没有完美的解决方案！你只能根据你的实际使用场景，选择其中最合适的一种了

