---
layout:     post
title:      "Weekly 085"
subtitle:   "Algorithm: Count Beautiful Substrings II; Review: Psyberg: Automated end to end catch up; Tips: ; Share: "
thumbnail-img: ""
date:       2023-12-10 21:10
author:     "dreamume"
tags: 		[it]
category:   it
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

# Table of Contents

1.  [Algorithm](#org9b3888b)
2.  [Review](#org805e930)
    1.  [Psyberg 之后的流水线](#orgad550f7)
    2.  [导航工作流：Psyberg 如何处理后达到的数据](#orge8c1242)
        1.  [1. Psyberg 的初始化](#org58ceeaf)
        2.  [2. 写-审核-发布（WAP）处理](#org9d65f38)
        3.  [3. Psyberg 提交](#org2f3bd58)
    3.  [呼叫](#org80a9e4b)
3.  [Tips](#org1a7fad1)
4.  [Share](#org90f2fbb)


<a id="org9b3888b"></a>

# Algorithm

Leetcode 2949: [Count Beautiful Substrings II](https://leetcode.com/problems/count-beautiful-substrings-ii/)

<https://dreamume.medium.com/leetcode-2949-count-beautiful-substrings-ii-95b68fade6b7>


<a id="org805e930"></a>

# Review

[Psyberg: Automated end to end catch up](https://netflixtechblog.com/3-psyberg-automated-end-to-end-catch-up-260fbe366fe2)

本文将介绍 Psyberg 帮助自动化不同流水线的端到端捕获，包括多维表

在之前的系列文章中，我们介绍了 Psyberg 和它的核心操作模型演进：无状态和状态数据处理。现在，让我们在合并 Psyberg 之后探讨一下我们流水线的状态


<a id="orgad550f7"></a>

## Psyberg 之后的流水线

让我们探讨一下不同的 Psyberg 模型对多数据流水线的帮助。我们回到采样客户生命周期：

![img](../img/psyberg_sample_customer_lifecycle.webp)

处理需求：

保持账号每小时的跟踪，例如 活跃/更新/降级/取消

解决方案：

一个潜在的处理如下：

1.  创建两个非状态事实表
    1.  注册
    2.  账号计划
2.  创建一个状态事实表
    1.  取消
3.  创建一个状态多维度每小时读取以上事实表且获取最新的账号状态

让我们看看这些如何与 Psyberg 集成来自动处理迟后达到数据和响应端到端捕获


<a id="orge8c1242"></a>

## 导航工作流：Psyberg 如何处理后达到的数据

我们跟随一个 Psyberg 有状态和无状态处理的一般化工作流结构；这帮助维护一致性和调试理解这些流水线更容易。如下是一个包括各个阶段的精确概括；对一个工作流说明的更详细的解释，请回到本系列的第二安装指导文章中


<a id="org58ceeaf"></a>

### 1. Psyberg 的初始化

工作流以 Psyberg 初始化步骤开始

-   输入：源表列表和需要的处理模型
-   输出：Psyberg 通过最近的高水印（HWM）和记录它们到会话元表来确定新的事件

会话元表然后读取确定流水线输入

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Psyberg 模式</th>
<th scope="col" class="org-left">Psyberg 会话元 / 流水线输入</th>
</tr>
</thead>

<tbody>
<tr>
<td class="org-left">无状态</td>
<td class="org-left">处理 URI</td>
</tr>


<tr>
<td class="org-left">有状态</td>
<td class="org-left">日期-小时范围来重处理</td>
</tr>
</tbody>
</table>


<a id="org9d65f38"></a>

### 2. 写-审核-发布（WAP）处理

这是在我们的 ETL 流水线中使用的一般化模型

1.  写

    应用 ETL 业务逻辑到步骤 1 中确认的输入数据且基于 Psyberg 模型写到一个不发布的 iceberg 快照
    
    <table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
    
    
    <colgroup>
    <col  class="org-left" />
    
    <col  class="org-left" />
    </colgroup>
    <thead>
    <tr>
    <th scope="col" class="org-left">Psyberg 模型</th>
    <th scope="col" class="org-left">写操作</th>
    </tr>
    </thead>
    
    <tbody>
    <tr>
    <td class="org-left">无状态</td>
    <td class="org-left">添加数据</td>
    </tr>
    
    
    <tr>
    <td class="org-left">有状态</td>
    <td class="org-left">覆盖数据</td>
    </tr>
    </tbody>
    </table>

2.  审核

    在阶段数据上运行各种质量检查。Psyberg 的元会话表用来确定包含批量运行的分区。几个审核，比如检查源和目的统计，执行在这个批量数据上

3.  发布

    如果审核通过，cherry-pick 阶段快照到发布数据到生产环境


<a id="org2f3bd58"></a>

### 3. Psyberg 提交

现在数据流水线成功执行，新的高清水印在初始化步骤确认提交到 Psyberg 高清水印元表。这确保工作流的下一个实例将获取更新的更新


<a id="org80a9e4b"></a>

## 呼叫

-   Psyberg 步骤从核心数据流水线隔离允许我们维护一个一致范型可被应用于变化的需求的非状态和状态处理流水线
-   这也允许我们更新 Psyberg 层而不接触工作流
-   跟 Python 和 Scala Spark 都兼容
-   调试/指出在每个运行中什么被加载在工作流参数和 Psyberg 元数据的帮助下很容易


<a id="org1a7fad1"></a>

# Tips

[System Design Interview - Distributed Cache](https://www.youtube.com/watch?v=iuqZvajTOyA)

让我们看一个典型的构建，一个有数据存储的 Web 应用程序。这个数据存储可能是一个数据库或一个 Web 服务。客户端发一个调用到 Web 应用程序，然后会发一个调用到数据存储，且结果返回到客户端。这个构建有几个问题。首先，到数据存储的调用可能花费很长时间来执行或可能使用太多系统资源。在内存中存储一些调用的结果会更好，这样这些结果获取和返回到客户端更快。如果数据存储下线或出现性能降级且调用到数据存储失败，我们的 Web 应用程序会如常处理请求，至少在一段时间内。这样，在内存中存储数据将帮助处理这些问题。当客户端请求到来，我们首先检查内存且尝试从内存获取信息。只有数据无效或脏时，我们调用到数据存储。为什么我们称它为分布式存储？因为数据总量很大不能存储到一个机器内存中且我们需要分割数据且存储到几个机器中

缓存无处不在。当我们设计分布式队列或通知服务或限速器，所有这些设计依赖某种缓存。让我们形式化需求。我们需要实现两个主要的操作：put 和 get。put 存储某个唯一键的对象到缓存，get 基于键从缓存获取对象。为简化，我们考虑键和值都为字符串。对非功能性需求，我们想要设计可扩展，高可用且快速缓存。高扩展性将帮助我们的缓存可处理增长的 put 和 get 请求数量。且能够处理在缓存中我们需要存储的增长数据总量。高有效性将帮助确保缓存中的数据在硬件故障时不丢失和网络分区时可访问。这将最小化缓存缺失和调用到数据存储的数量。高性能是我们对缓存需求的数量。缓存的整个点是对每个请求都很快

第一个提示，在一个面试期间，当我们需要定义需求，功能性需求相对容易。但非功能性需求不容易定义。如果你需要设计一个分布式系统，首先想一下如下 3 个需求：可扩展性，有效性和性能。如果数据持久化很重要想一下持久性。这 4 个将给你和你的面试官大量地讨论空间。如果你重拾 CAP 理论，有效性需求会取代一致性。现在我们简化不在这里深入这个话题

第二个提示，记住面试官是你的朋友且你们都有相同的目标。你的目标是提供尽量多的正面数据观点，面试官的目标是收集尽量多的数据观点。实际上，这意味着你应该以一些简单小的步骤开始处理任意设计问题。并在每个下一步中演进你的解决方案。这是一个双赢局面。你展示进展，能力来处理分歧和简化事情。然而，面试官获得所有必要的数据观点来放入表中并在面试循环中和其他面试官讨论你的方案。基于这些，我们首先以本地缓存开始

我们以一个服务器开始，且需要实现一个基本的内存数据存储，有有限的容量。本地缓存实现是一个算法问题。我们需要数据结构和一个算法来存储获取数据。首先出现在头脑里的数据结构是哈希表。我们添加键值对到哈希表且在常量时间内获取它们。但当我们达到最大哈希表大小且不能添加更多元素时，我们需要在新数据插入前从哈希表中剔除某些旧数据。要剔除什么数据？有很多种不同的处理，所有称为驱逐或替换策略。最简单的其中之一是实现最少最近使用策略，我们首先丢弃最少最近使用的条目。但哈希表不跟踪最近使用的条目。我们需要更多的数据结构来跟踪使用的条目。参考 LRU 算法

现在考虑分布式。我们以一个直接的想法开始，当我们移动最少最近使用缓存到它的主机。这个好处是我们现在能使每个主机存储数据簇，称为切片。因为数据分割到几个主机，我们现在可存储更多数据到内存。服务主机知道所有切片，且它们转发 put 和 get 请求到特定的切片。相同的想法，但一个不同的实现是在服务主机上使用缓存。我们在服务主机上以一个单独进程运行缓存。且数据也分片。和第一种相似的是，当服务需要调用缓存，它获取有存储数据的切片并开始一个调用。让我们称这些选项为分布式缓存簇和共同位置缓存。看一下每个选项的好处。第一种帮助从服务资源隔离缓存资源，缓存和服务不共享内存和 CPU 资源。且自己可扩展。可用于多个服务。且我们可利用相同的簇在我们的团队中跨多个微服务。也给了我们选择硬件的灵活性。我们可选择很多内存和高网络带宽的硬件主机。公有云现在提供各种内存优化硬件。对共同位置缓存，最大的好处是我们不需要一个独立的簇。这帮助节省硬件成本且通常比独立簇更少的密集操作，服务和缓存扩展同时进行。当需要时我们只添加更多的主机到服务簇

缓存客户端如何决定哪个缓存分片来调用？让我们讨论一个简单的处理。基于我们计算哈希的条目键和一些哈希函数。我们通过一些缓存主机来分割这个哈希值。用余数。我们把这个余数作为缓存主机数组的索引。


<a id="org90f2fbb"></a>

# Share

