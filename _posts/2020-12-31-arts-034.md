---
layout:     post
title:      "Weekly 034"
subtitle:   "Algorithm: Top K Frequent Elements; Review: Epidemic Algorithms for Replicated Database Maintenance; Share: Scalability for Dummies - Part 2: Database"
thumbnail-img: ""
date:       2020-12-31 20:00
author:     "dreamume"
tags: 		[it]
category:   it
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

# Table of Contents

1.  [Algorithm](#orga951a5f)
2.  [Review](#org07b2e70)
    1.  [简介](#org0f41490)
        1.  [动机](#orga1658e7)
        2.  [相关工作](#org5b8ea38)
        3.  [本文计划](#org4ac3459)
    2.  [基本技术](#org6886af2)
        1.  [记号](#org8879d19)
        2.  [直接邮件](#orgb0bed91)
        3.  [反熵](#org79a41d4)
3.  [Tips](#org92d2c69)
4.  [Share](#orgea2023f)


<a id="orga951a5f"></a>

# Algorithm

Leetcode 343: 


<a id="org07b2e70"></a>

# Review

Epidemic Algorithms for Replicated Database Maintenance

<http://bitsavers.informatik.uni-stuttgart.de/pdf/xerox/parc/techReports/CSL-89-1_Epidemic_Algorithms_for_Replicated_Database_Maintenance.pdf>


<a id="org0f41490"></a>

## 简介

考虑数据库在大型、各种各样、不可靠且缓慢改变的成百上千个网站的网络环境下的对许多网站复制，我们检查一些方法在站点间达成并维持一致。每个数据库更新被注入在单个站点且必须广播到所有其他站点或被后续的更新替代。站点可变成全一致仅当所有的更新活动已停止且系统暂时变得安静。另一方面，假设一个合理的更新速度，大多数信息在任意给定站点是当前的。这个一致性的松散形式在实际中很有用。我们的目标是设计高效稳定的算法且能很好的使用站点增长的扩展

在检查算法解决这个问题的可考虑重要因素包括

-   更新需要的时间广播到所有站点，且
-   广播单个更新产生的网络流量。理想网络流量是跟更新乘以服务器数量成比例的，但一些算法产生更多的流量

本文我们呈现分析，使用扩散更新的一些策略的模拟结果和实践经验。方法检查包括；

1.  直接邮件：每个新的更新直接从该站点邮件到所有其他站点。这是有效的但不是完全可靠因为个别站点不总是知道所有其他站点且邮件有时会丢失
2.  反熵：每个站点随机规律地选择另一个站点且交换它解决的两者之间不同的数据库内容。反熵是非常可靠的但需要检测数据库内容且不能使用太频繁。分析和模拟显示反熵，可靠、广播更新比直接邮件慢很多
3.  谣言传播：站点初始化为“无知的”，当一个站点接收到一个新的更新它变成一个“热谣言“；当站点持有一个热谣言，它定期随机选择一个其他站点并确保该站点已看到该更新；当站点已经尝试共享一个热谣言给很多站点以看到该更新，站点停止对待谣言为热的且不再广播该更新。谣言循环可能比反熵更频繁因为它们在每个站点上要求更少的资源，但有几率导致更新不会达到所有站点

反熵和谣言传播都是传染进程的例子，传染理论的结果是可应用的。这些机制的理解极大地得利于现存的流行病数学理论，虽然我们的目的不同。更多地，我们有设计流行病机制的自由，我们采用流行病领域的术语并称有一个更新要共享的站点为共享该更新的感染。一个站点为易感染的如果它还未接收到更新；一个站点被删除如果它接收到更新但不再共享更新。反熵是一个简单流行病的例子：站点总是要么易感染要么已感染

选择合作者统一结果会有高网络流量，使我们考虑相关分布其选择趋向于附近的服务器。施乐公司因特网在实际拓扑上的分析和模拟揭露了反熵和谣言传播的分布收敛和统一分布一样快，当减少每个连接的平均和最大流量时。结果反熵算法安装在施乐公司因特网且得到显著的性能改进

我们将指出数据库的扩展复制是昂贵的。它将通过数据库分层分解或缓存尽可能避免。即使这样，我们论文的结果是有趣的因为它们显示了显著的重复可被达到，通过简单的算法，在分层的每层或缓存方案上


<a id="orga1658e7"></a>

### 动机

这个工作起源于在施乐公司Clearinghouse服务器的学习。公司组成数百个以太网用网关连接且许多不同容量的电话线。几千个工作站，服务器和计算主机。一个从日本机器来的包到欧洲可能经过了最多14个网关和7个电话线

Clearinghouse服务维护3层、分层名称到机器地址、用户唯一标识等的传递。分层分区上两层的名字空间到一个域集合。每个域可能存储（重复）一部分，或全部的Clearinghouse服务器，有数百个

一些域事实上存储在CIN的所有Clearinghouse服务器上。在1986年初，许多网络观察性能问题可被跟踪到在它们的高层复制域创建尝试达成一致流量上。随着网络增长，更新域存储在甚至几个服务器上广播也非常慢

当我们开始处理该问题，Clearinghouse服务器被用来直接邮件和反熵。反熵运行在每个域，理论上，每天本地时间在午夜到早上6点一次（每个服务器）。事实上，服务器由于网络负载经常不能在允许时间内完成反熵工作

我们首次发现反熵跟着一个重邮步骤：正确的数据库值被邮给之前两个反熵参与者分歧的所有站点。更多地站点间不同意导致更多的流量。对一个存储在300个站点的域，每天晚上可能有90000个邮件信息被引入。这远超网站的容量，且结果导致所有网络服务下线：邮件、文件传输、名字查询等等

因为重邮步骤不能在我们观察的大网络上工作，它被禁止。更进一步分析显示这没有效率：某些网络中key链接仍然被反熵流量过载


<a id="org5b8ea38"></a>

### 相关工作

本文算法想要维护一个广复制目录，或名称查找，数据库。跟使用基于交易的机制不同这里尝试达成“一次拷贝序列化“，我们使用驱动复制节点达到最终同意的机制。这样的机制被Johnson et al首先提出，并用在Grapevine和Clearinghouse中。这些系统的经验使我们知道一些问题仍在；特别地，一些更新（低可能性）不能到达所有站点。Lampson提出一个分层数据结构避免高复制，但仍然需要一些每个部件的复制，6到12个服务器。主站点复制数据库的更新算法被提议通过请求应用于单个站点来同步更新；更新站点负责广播更新到所有节点。DARPA域系统，例如，使用这种排序的算法。主站点更新避免了本文描述的分布式更新的问题但导致了集中控制

有两个特征区别我们的算法和之前的机制。首先，之前的机制依赖各种从底层通讯协议的保证和维持一致的分布式控制结构。例如，在Clearinghouse中更新的初始分布依赖于底层保障邮件协议，其在实际中由于物理查询过载经常故障，即使邮件队列维护在磁盘存储。Sarin和Lynch展现了一个分布式算法用来丢弃过时的数据，其依赖于保障，合适地顺序，消息转发及每个服务器描述相同数据库的其他所有服务器的具体数据结构。Lampson et al.预想一个服务器环上的确定性移动，被一个服务器到下一个的指针持有。这些算法依赖各种分布式数据结构的排斥一致属性，例如，在Lampson算法中指针必须定义为一个环。本文算法仅依赖重复消息的最终转发，不需要服务器的数据结构描述信息

其次，本文描述的算法是随机的，即每个服务器的算法使用独立的随机选择。不同地是，之前的机制是确定性的。例如，在反熵和流言触发算法中，一个服务器做一个随机选择要么依然感染或被删除。随机选择的使用避免我们使用这样的声明：“信息将以时间成比例的收敛到网络直径。“我们最好声称在更进一步的更新缺失的情况下，信息不能收敛的概率随时间指数级增长。另一方面，我们相信随机协议的使用使我们的算法可用简单的数据结构直接实现


<a id="org4ac3459"></a>

### 本文计划

第一节形式化复制数据库的记号和展现达成一致性的基本技术。第二节描述从数据库删除数据项的技术；删除比其他改变更复杂因为删除数据项必须呈现一个替代者直到删除的消息扩散到所有站点。第3节展现反熵和流言合作者的选择在非统一空间分布上的模拟和分析结果


<a id="org6886af2"></a>

## 基本技术

本节介绍复制数据库记号和呈现基本直接邮件，反熵和复杂传染协议及它们的分析


<a id="org8879d19"></a>

### 记号

考虑一个网络包含n个站点的集合S，每个存储一个数据库的拷贝。数据库拷贝站点 $ s \\in S $是时间变动的不完整函数

$ \\begin{equation} s.ValueOf: K \\to (v: V \\times t : T) \\end{equation} $

K是键的集合（名称），V是值的集合，T是时间戳的集合。V包含不同的元素NIL但未指明。T是按<总序。我们解释s.ValueOf[k] = (NIL, t)为该项目确认为k已经被从数据库中删除。即，从数据库客户端来看，s.ValueOf[k] = (NIL, t)就是s.ValueOf[k]未定义

第1.2和1.3节所述的分布式技术是简单的，通过考虑一个数据库对单个名称存储值和时间戳。所以我们说

$ \\begin{equation} s.ValueOf \\in (v: V \\times t: T) \\end{equation} $

例如，s.ValueOf是有序对包含一个值和一个时间戳。如之前所述，第一个元素可能是NIL，表示该项目在第二个元素所示的时间被删除

更新分布式进程的目标是驱动系统使得

$ \\begin{equation} \\forall s,s' \\in S, s.ValueOf = s'.ValueOf \\end{equation} $

在任意站点有一个操作客户端必须调用来更新数据库，s:

$ \\begin{equation} Update[v: V] \\equiv s.ValueOf \\gets (v, Now[]) \\end{equation} $

Now是一个函数返回全局唯一时间戳。Now[]返回的时间戳将是当前的格林尼治时间 - 如果不是，算法将不以实际效果工作。感兴趣的读者可参考Clearinghouse[Op]和Grapevine[Bi]论文进一步地描述时间戳在构建一个有用的数据库中的角色。对我们的目的来说，必要地知道该元组有一个更大的时间戳将总是被替换成一个更小的时间戳


<a id="orgb0bed91"></a>

### 直接邮件

直接邮件策略当一个更新发生时尝试通知所有其他站点。基本的算法执行在一个站点上：

$ \\begin{equation} \\text{FOR EACH } s' \\in S \\text{ DO} \\\\ \\qquad PostMail[to: s', msg: ("Update", s.ValueOf)] \\\\ \\qquad ENDLOOP \\end{equation} $

一旦接受到消息("Update", (v,t))，站点执行：

$ \\begin{equation} \\text{IF } s.ValueOf.t < t \\text{ THEN} \\\\ \\qquad s.ValueOf \\gets (v, t) \\end{equation} $

PostMail操作希望是附近的，但不完全可靠。它把消息放入队列使得发送者不被延迟。队列保持在邮件服务器的稳定存储这样它们不被服务器崩溃影响。尽管，PostMail可能失败：消息可能被丢弃当队列满了或它们的目标长时间不能访问。除了邮件系统的这种故障，直接邮件也可能失败当源站点更新时没有S的精确知识，站点集合。

在Grapevine系统[Bi]中，检测和校正直接邮件故障的职责策略被指定给管理网络的人员。只有在几十个服务器的网络中这种处理方式才能很好适配

每个更新直接邮件产生n个消息，每个消息游走于源和目的之间的网络连接。这样（连接 $ \\cdot $ 消息）流量单位跟站点数量乘以站点间平均距离成比例


<a id="org79a41d4"></a>

### 反熵

Grapevine设计者认识到直接邮件处理故障在大型网络中超出了人的能力范围。他们提出反熵作为一个机制运行在从这样的故障中自动恢复的背景环境中。反熵不作为Grapevine的一部分来实现，但设计能在不变动的情况下适配Clearinghouse。它最基本的形式反熵被表达为如下在每个站点s上定期执行的算法：

$ \\begin{equation} \\text{FOR SOME } s' \\in S \\text{ DO} \\\\ \\qquad ResolveDifference[s, s'] \\\\ \\qquad ENDLOOP \\end{equation} $

ResolveDifference[s, s']需要两个服务器合作，依赖于它的设计，它的有效方法可被表达为如下三种方式之一，称为push，pull和push-pull：

\\begin{equation} ResolveDifference: PROC[s, s'] = \\{ -- push \\\\ \\qquad \\text{IF } s.ValueOf.t > s'.ValueOf.t \\text{ THEN} \\\\ \\qquad \\qquad s'.ValueOf \\gets s.ValueOf \\\\ \\qquad \\} \\end{equation} $

\\begin{equation} ResolveDifference: PROC[s, s'] = \\{ -- pull \\\\ \\qquad \\text{IF } s.ValueOf.t > s'.ValueOf.t \\text{ THEN} \\\\ \\qquad \\qquad s'.ValueOf \\gets s.ValueOf \\\\ \\qquad \\} \\end{equation} $

\\begin{equation} ResolveDifference: PROC[s, s'] = \\{ -- push-pull \\\\ \\qquad \\text{SELECT TRUE FROM } \\\\ \\qquad \\qquad s.ValueOf.t > s'.ValueOf.t \\Rightarrow s'.ValueOf \\gets s.ValueOf; \\\\ \\qquad \\qquad s.ValueOf.t < s'.ValueOf.t \\Rightarrow s.ValueOf \\get s'.ValueOf; \\\\ \\qquad \\qquad ENDCASE \\Rightarrow NULL; \\\\ \\qquad \\} \\end{equation} $


<a id="org92d2c69"></a>

# Tips

-   知识分类型，一些大量消耗脑细胞的需要放慢速度有效吸收，而一些更偏知识型的，可以提速以了解阅读为主
-   注意前提知识，在学习新的知识前先把其需要的前提知识先学好，有层次的推进，否则容易卡壳
-   或许每个阶段有每个阶段适合自己的学习方法，在未找到更好的方法之前先要坚持使用目前认为最适合的方法，并清楚当前所用方法的缺陷及可能改进方向，每过一段时间或觉得当前方法不再适应时，要尝试一些新的方法


<a id="orgea2023f"></a>

# Share

Scalability for Dummies - Part 2: Database

<https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database>

在第一部分之后，你的服务器现在可水平扩展且你可服务数千个并行请求。但你的应用程序变得越来越慢且最终无法工作。原因：你的数据库。是MySQL？

现在需要的改变比添加更多的复制节点更加激进且需要一些勇气。最后，你可选择2条路：

路径1是继续使用MySQL并使他运行。租用一个数据库管理员（DBA）告诉他做主从复制（从节点读，主节点写）且添加内存来升级你的主服务器。在数月时间，你的DBA将提及“分片”，“denormalization", "SQL tunning"且担心下周过多需求。这时每个保持数据库运行的新的行为 将更昂贵且耗时。如果你的数据集较小且容易迁移你可能选择路径2更好

路径2意味着从开始阶段就denormalize right且在任意数据库查询中不包含Join。你可停留于使用MySQL，且像NoSQL数据库一样使用它，否则你可以切换到一个更好更易扩展的NoSQL数据库如MongoDB或CouchDB。Join现在需要在你的应用程序代码中做。这个步骤你做的越快将来需要修改的代码越少。但即使你成功切换到最新最好的NoSQL数据库且让你的应用程序做数据集join，不久你的数据库请求将变得越来越慢，你需要引入缓存

