---
layout:     post
title:      "Weekly 062"
subtitle:   "Algorithm: ; Review: Notes about Media Technology; Tips: Notes about Media Technology in mobile platform; Share:"
thumbnail-img: ""
date:       2022-08-08 20:00
author:     "dreamume"
tags: 		[it]
category:   it
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

# Table of Contents

1.  [Algorithm](#orgc2e6ec3)
2.  [Review](#org8075d53)
3.  [Tips](#org7497310)
    1.  [iOS 平台音频渲染（一）：使用 AudioQueue 渲染音频](#org6d5da76)
        1.  [AVAudioSession](#org652fc80)
        2.  [AudioQueue 详解](#orge1a3583)
        3.  [AudioQueue 运行流程](#org5b25c36)
        4.  [iOS 平台的音频格式](#org1eb44eb)
4.  [Share](#org33b8af6)


<a id="orgc2e6ec3"></a>

# Algorithm


<a id="org8075d53"></a>

# Review

音视频技术入门课    刘岐


<a id="org7497310"></a>

# Tips

移动端音视频开发实战    展晓凯


<a id="org6d5da76"></a>

## iOS 平台音频渲染（一）：使用 AudioQueue 渲染音频


<a id="org652fc80"></a>

### AVAudioSession

它以单例的形式存在，用于管理与获取 iOS 设备音频的硬件信息

1.  基本设置

    1.  根据我们需要硬件设备提供的能力来设置类别
        
            [audioSession setCategory:AVAudioSessionCategoryPlayback error:&error];
    
    2.  设置 I/O 的 Buffer，Buffer 越小说明延迟越低
        
            NSTimeInterval bufferDuration = 0.002;
            [audioSession setPreferredIOBufferDuration:bufferDuration error:&error];
    
    3.  设置采样频率，让硬件设备按照设置的采样率来采集或者播放音频
        
            double hwSampleRate = 44100.0;
            [audioSession setPreferredSampleRate:hwSampleRate error:&error];
    
    4.  当设置完毕所有参数之后就可以激活 AudioSession 了
        
            [audioSession setActive:YES error:&error];

2.  深入理解 AudioSession

    关于 Category 和 CategoryOptions
    
    1.  Category 是向系统描述应用需要的能力，常用的分类如下
        1.  AVAudioSessionCategoryPlayback：用于播放录制音乐或者其他声音的类别，如果要在应用程序转换到后台时继续播放（锁屏情况下），在 Xcode 中设置 UIBackgroundModes 即可。默认情况下，使用此类别意味着，应用的音频不可混合，激活音频会话将中断其他不可混合的音频会话。如果使用混音，则使用 AVAudioSessionCategoryOptionMixWithOthers
        2.  AVAudioSessionCategoryPlayAndRecord：同时需要录音（输入）和播放（输出）音频的类别，例如 K 歌、RTC 场景。注意：用户必须打开音频录制权限（iPhone 麦克风权限）
    2.  CategoryOptions 是向系统设置类别的可选项，具体分类如下
        1.  AVAudioSessionCategoryOptionDefaultToSpeaker：此选项只能在使用 PlayAndRecord 类别时设置。它用于保证在没有使用其他配件（如耳机）的情况下，音频始终会路由至扬声器而不是听筒。而如果类别设置的是 Playback，系统会自动使用 Speaker 进行输出，无需进行此项设置
        2.  AVAudioSessionCategoryOptionAllowBluetooth：此选项代表音频录入和输出全部走蓝牙设备，仅可以为 PlayAndRecord 还有 Record 这两个类别设置这个选项，注意此时播放和录制的声音音质均为通话音质（16kHz），适用于 RTC 的通话场景，但不适用于 K 歌等需要高音质采集与播放的场景
        3.  AVAudioSessionCategoryOptionAllowBluetoothA2DP：此选项代表音频可以输出到高音质（立体声、仅支持音频输出不支持音频录入）的蓝牙设备中。如果使用 Playback 类别，系统将自动使用这个 A2DP 选项，如果使用 PlayAndRecord 类别，需要开发者自己手动设置这个选项，音频采集将使用机身内置麦克风（在需要高音质输入输出场景下可以设置成这个）
        4.  监听音频焦点抢占，一般在检测到音频被打断的时候处理一些自己业务上的操作，比如暂停播放音频等，代码如下
            
                [[NSNotificationCenter defaultCenter] addObserver:self 
                                                         selector:@selector(audioSessionInterruptionNoti:)
                                                             name:AVAudioSessionInterruptionNotification
                                                           object:[AVAudioSession sharedInstance]];
                
                - (void)audioSessionInterruptionNoti:(NSNotification *)noti {
                  AVAudioSessionInterruptionType type = 
                    [noti.userInfo[AVAudioSessionInterruptionTypeKey] intValue];
                  if (type == AVAudioSessionInterruptionTypeBegan) {
                    // do something
                  }
                }
        5.  监听声音硬件路由变化，当检测到插拔耳机或者接入蓝牙设备的时候，业务需要做一些自己的操作，代码如下
            
                [[NSNotificationCenter defaultCenter] addObserver:self 
                                                         selector:@selector(audioRouteChangeListenerCallback:)
                                                             name:AVAudioSessionRouteChangeNotification
                                                           object:nil];
                
                - (void)audioRouteChangeListenerCallback:(NSNotification *)notification {
                  NSDictionary* interruptionDict = notification.userInfo;
                  NSInteger routeChangeReason = 
                    [[interruptionDict valueForKey:AVAudioSessionRouteChangeReasonKey] intergerValue];
                  if (routeChangeReason == AVAudioSessionRouteChangeReasonCategoryChange ||
                      routeChangeReason == AVAudioSessionRouteChangeReasonCategoryOverride) {
                    // do something
                  }
                }
        6.  申请录音权限，首先判断授权状态，如果没有询问过，就询问用户授权，如果拒绝了就引导用户进入设置页面手动打开
            
                AVAuthorizationStatus status = 
                  [AVCaptureDevice authorizationStatusForMediaType:AVMediaTypeAudio];
                if (status == AVAuthorizationStatusNotDetermined) {
                  [[AVAudioSession sharedInstance] requestRecordPermission:^(BOOL granted) {
                    }];
                 } else if (status == AVAuthorizationStatusNotRestricted || 
                            status == AVAuthorizationStatusDenied) {
                  // 引导用户跳入设置页面
                 } else {
                  // 已授权
                 }
    
    注意从 iOS 10 开始，所有访问任何设备的应用都必须静态声明其意图。为此，应用程序现在必须在其 Info.plist 文件中包含 NSMicrophoneUsageDescription 键，并为此密钥提供目的字符串


<a id="orge1a3583"></a>

### AudioQueue 详解

iOS 为开发者在 AudioToolbox 这个 framework 中提供了一个名为 AudioQueueRef 的类，AudioQueue 内部会完成以下职责：

-   连接音频的硬件进行录音或者播放
-   管理内存
-   根据开发者配置的格式，调用编解码器进行音频格式转换

AudioQueue 暴露给开发者的接口如下

-   使用正确的音频格式、回调方法等参数，创建出 AudioQueueRef 对象
-   为 AudioQueueRef 分配 Buffer，并将 Buffer 入队，启动 AudioQueue
-   在 AudioQueueRef 的回调中填充指定格式的音频数据，并且重新入队
-   暂停、恢复等常规接口


<a id="org5b25c36"></a>

### AudioQueue 运行流程

分为启动和运行阶段，启动阶段主要是应用程序配置和启动 AudioQueue；运行阶段主要是 AudioQueue 开始播放之后回调给应用程序填充 buffer，并重新入队，3 个 buffer 周而复始地运行起来；直到应用程序调用 AudioQueue 的 Pause 或者 Stop 等接口

1.  启动阶段

    1.  配置 AudioQueue
        
            AudioQueueNewInput(&dataformat, playCallback, (__bridge void *)self, 
                               NULL, NULL, 0, &queueRef);
        
        dataformat 就是音频格式，函数返回值如果为 noErr 则说明配置成功
    
    2.  分配 3 个 Buffer，并且依次灌到 AudioQueue 中
        
            for (int i = 0; i < kNumberBuffers; ++i) {
              AudioQueueAllocateBuffer(queueRef, bufferBytesSize, &buffers[i]);
              AudioQueueEnqueueBuffer(queueRef, buffers[i], 0, NULL);
             }
    
    3.  调用 Play 方法进行播放
        
            AudioQueueStart(queueRef, NULL);

2.  运行阶段

    1.  AudioQueue 启动之后会播放第一个 buffer
    2.  当播放完第一个 buffer 之后，会继续播放第二个 buffer，但是与此同时将第一个 buffer 回调给业务层由开发者进行填充，填充完毕重新入队
    3.  第二个 buffer 播放完毕后，会继续播放第三个 buffer，与此同时会将第二个 buffer 回调给业务层由开发者进行填充，填充完毕重新入队
    4.  第三个 buffer 播放完毕后，会继续循环播放队列中的第一个 buffer，也会将第三个 buffer 回调给业务层由开发者进行填充，填充完毕重新入队
    
        static void playCallback(void *aqData, AudioQueueRef inAQ, AudioQueueRef inBuffer) {
          KSAudioPlayer *player = (__bridge KSAudioPlayer *)aqData;
          // fill data
          AudioQueueEnqueueBuffer(player->queueRef, inBuffer, numPackets, player.mPacketDescs);
        }

3.  AudioQueue 中 Codec 运行流程

    1.  开发者配置 AudioQueue 的时候告诉 AudioQueue 具体编码格式
    2.  开发者在回调函数中按照原始格式填充 buffer
    3.  AudioQueue 会自己采用合适的 Codec 将压缩数据解码成 PCM 进行播放


<a id="org1eb44eb"></a>

### iOS 平台的音频格式

音频格式 ASBD（AudioSessionBasicDescription），以下对一些字段进行解释

-   mFormatID 这个参数用来指定音频的编码格式，此处音频编码格式指定为 PCM 格式
-   mFormatFlags 是用来描述声音表示格式的参数，代码中的第一个参数指定每个 sample 的表示格式是 Float 格式。这个类似于我们之前讲解的每个 sample 使用两个字节（Sint16）来表示；然后后面的参数 NonInterleaved，如果指定 NonInterleaved，那么左声道在 mBuffers[0] 里，右声道在 mBuffers[1] 里，如果是 Interleaved，左右声道数据交错排列在 mBuffers[0] 中
-   mBitsPerChannel 表示一个声道的音频数据用多少位来表示，我们知道采样使用 Float 来表示，所以这里就使用 8 乘以每个采样的字节数来赋值
-   最后是参数 mBytesPerFrame 和 mBytesPerPacket，如果是 NonInterleaved，就赋值为 bytesPerSample，否则为 bytesPerSample \* channels

如果要播放一个 MP3 或 M4A 文件，如下代码设置 ASBD

    NSURL *fileURL = [NSURL URLWithString:filePath];
    OSStatus status = 
      AudioFileOpenURL((__bridge CFURLRef)fileURL, kAudioFileReadPermission,
                       kAudioFileCAFType, &_mAudioFile);
    if (status != noErr) {
      NSLog(@"open file error");
     }
    
    // 获取文件格式
    UInt32 dataFormatSize = sizeof(dataFormat);
    AudioFileGetProperty(_mAudioFile, kAudioFilePropertyDataFormat, 
                         &dataFormatSize, &dataFormat);


<a id="org33b8af6"></a>

# Share

